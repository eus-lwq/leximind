# LLaMA Inference Quick Guide

To perform inference using a LoRA-finetuned LLaMA model via `llama-factory` and `vLLM`, follow the steps below.

First, clone the repository:

```bash
git clone git@github.com:Yuan-33/llama-factory.git
