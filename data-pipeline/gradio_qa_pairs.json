[
  {
    "question": "How I can realtime update the Ui when I receive a request upon FastAPI?",
    "answer": "<p>Only method which works for me is</p>\n<pre><code>def function():\n    return log.logstr\n\nTextbox(value=function, ..., every=1)\n</code></pre>\n<p>It runs <code>function</code> every 1 second, and this <code>function</code> returns current content in log.</p>\n<p>Doc: <a href=\"https://www.gradio.app/docs/gradio/textbox\" rel=\"nofollow noreferrer\">Gradio Textbox</a></p>\n<hr />\n<p>Full code:</p>\n<pre><code>import os\nimport gradio as gr\nfrom fastapi import FastAPI, Request\nimport uvicorn\nimport threading\nfrom typing import List\nfrom datetime import datetime\n\napi = FastAPI()\n\n# Shared logs\n\nclass Log():\n    def __init__(self):\n        self._logs: List[str] = []\n        self.logstr=&quot;&quot;\n\n    def log_message(self,msg: str):\n        timestamp = datetime.now().strftime(&quot;%H:%M:%S&quot;)\n        self._logs.append(f&quot;[{timestamp}] {msg}&quot;)\n        self.logstr=&quot;\\n&quot;.join(self._logs)\n\nlog = Log()\nlog_state = gr.State(log)\n\n# === FastAPI Setup ===\n\n@api.post(&quot;/log&quot;)\nasync def receive_log(request: Request):\n    data = await request.body()\n    msg = f&quot;API received: {data}&quot;\n    log.log_message(msg)\n    gr.update(value=log.logstr)\n    #print('data:', data)\n    return {&quot;status&quot;: &quot;logged&quot;, &quot;message&quot;: msg}\n\ndef run_api():\n    #print('run FastAPI')\n    api_port = int(os.environ.get(&quot;API_PORT&quot;, 8000))\n    uvicorn.run(api, host=&quot;0.0.0.0&quot;, port=api_port)\n\n# === Gradio UI ===\n\ndef get_logs():\n    #print('run: get_logs')\n    return log.logstr\n\nwith gr.Blocks() as ui:\n    gr.Markdown(&quot;## üìù Incoming HTTP Requests&quot;)\n    log_box = gr.Textbox(label=&quot;Logs&quot;, value=get_logs, lines=20, every=1)\n    # Trigger the refresh when the log state is updated\n\ndef run_gradio():\n    gradio_port = int(os.environ.get(&quot;GRADIO_PORT&quot;, 7860))\n    ui.launch(server_port=gradio_port)\n\n# === Start Both ===\n\nif __name__ == &quot;__main__&quot;:\n    threading.Thread(target=run_api, daemon=True).start()\n    run_gradio()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/79598793/how-i-can-realtime-update-the-ui-when-i-receive-a-request-upon-fastapi"
  },
  {
    "question": "What am I doing wrong with gradio.Dropdown? How to dynamically modify the choices of a Dropdown?",
    "answer": "<pre><code>import gradio as gr\n\nlanguages = ['spanish', 'english']\nhomeworks = {'spanish': ['hola', 'bien', 'gracias'], 'english': ['hello', 'good', 'thank you']}\n\ndef rs_change(rs):\n    print(homeworks[rs])\n    return gr.Dropdown.update(choices=homeworks[rs])\n\ndef test():\n    pass\n\ndef webui():\n    inputs = [\n        gr.Dropdown(choices=languages),\n        gr.Dropdown(choices=[]),\n        ]\n\n    with gr.Blocks() as app:\n        gr.Interface(\n            fn=test,\n            inputs=inputs,\n            outputs=None\n        )\n\n        inputs[0].select(fn=rs_change, inputs=inputs[0], outputs=inputs[1])\n\n    app.launch(server_port=1111)\n\nwebui()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76693922/what-am-i-doing-wrong-with-gradio-dropdown-how-to-dynamically-modify-the-choice"
  },
  {
    "question": "How can I show the progress of a script running in Gradio?",
    "answer": "<p>If you're asking for something like a progress bar you can use either tqdm or rich module</p>\n",
    "link": "https://stackoverflow.com/questions/75480945/how-can-i-show-the-progress-of-a-script-running-in-gradio"
  },
  {
    "question": "How to avoid auto-scroll when add a lot of text in a `TextArea` in Gradio?",
    "answer": "<p>One can use the <code>autoscroll=False</code> parameter:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\n\ndef show_text():\n    return '\\n'.join([f'test{i}' for i in range(50)])  # Simulated long text\n\nwith gr.Blocks() as demo:\n    text_area = gr.TextArea(label=&quot;Output&quot;, lines=10, max_lines=20,  autoscroll=False)\n    btn = gr.Button(&quot;Show Text&quot;)\n    btn.click(fn=show_text, outputs=text_area)\n\ndemo.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/79589019/how-to-avoid-auto-scroll-when-add-a-lot-of-text-in-a-textarea-in-gradio"
  },
  {
    "question": "Gradio &quot;AttributeError: &#39;Image&#39; object has no attribute &#39;proxy_url&#39;&quot;",
    "answer": "<p>if I remove <code>components=</code> from <code>show_startup_quotes()</code> (similar to <a href=\"https://www.gradio.app/docs/gradio/dataset#examples\" rel=\"nofollow noreferrer\">example in Dataset doc</a>) then it doesn't raise error.</p>\n<pre><code>def show_startup_quotes():\n    return gr.Dataset(samples=startup_quotes)\n</code></pre>\n<p>Tested on Linux Mint, Python 3.13, Gradio 5.19</p>\n<hr />\n<p>By The Way:</p>\n<p>Because you have <code>components=[textbox, image]</code> (first textbox, next image) in <code>with gr.Blocks() as demo</code> - so list should also have elements in this order (first textbox, next image)</p>\n<pre><code>philosophy_quotes = [\n    [&quot;I think therefore I am.&quot;, white_image], \n    [&quot;The unexamined life is not worth living.&quot;, white_image]\n]\n\nstartup_quotes = [\n    [&quot;Ideas are easy. Implementation is hard&quot;, red_image],\n    [&quot;Make mistakes faster.&quot;, red_image]\n]\n</code></pre>\n<hr />\n<p>Full working code:</p>\n<pre><code>import gradio as gr\nfrom PIL import Image\n\nwhite_image = Image.new(&quot;RGBA&quot;, (16, 16), color=(0, 0, 0, 0))\nred_image = Image.new(&quot;RGBA&quot;, (16, 16), color=(255, 0, 0, 255))\n\nphilosophy_quotes = [\n    [&quot;I think therefore I am.&quot;, white_image], \n    [&quot;The unexamined life is not worth living.&quot;, white_image]\n]\n\nstartup_quotes = [\n    [&quot;Ideas are easy. Implementation is hard&quot;, red_image],\n    [&quot;Make mistakes faster.&quot;, red_image]\n]\n\ndef show_startup_quotes():\n    return gr.Dataset(samples=startup_quotes)\n\nwith gr.Blocks() as demo:\n    textbox = gr.Textbox()\n    image = gr.Image(visible=False, type=&quot;pil&quot;)\n    dataset = gr.Dataset(components=[textbox, image], samples=philosophy_quotes)\n    button = gr.Button()\n\n    button.click(show_startup_quotes, None, dataset)\n\ndemo.launch()\n</code></pre>\n<p>Result (after clicking button <code>Run</code>):</p>\n<p><a href=\"https://i.sstatic.net/XInrosSc.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/XInrosSc.png\" alt=\"enter image description here\" /></a></p>\n",
    "link": "https://stackoverflow.com/questions/79571015/gradio-attributeerror-image-object-has-no-attribute-proxy-url"
  },
  {
    "question": "Using custom JS event handler inside Gradio",
    "answer": "<p>So I needed similar functionality (passing values from javascript event listener to python gradio) for listening to user mousedown/mouseup events and didn't want to create a custom component and register listeners that way. Here's the (pretty hacky) way I went about it:</p>\n<pre class=\"lang-py prettyprint-override\"><code>\nimport gradio as gr\n\nscript = &quot;&quot;&quot;\nfunction setupClick() {\n    console.log(&quot;BEFORE&quot;);\n    const video = document.getElementById(&quot;video_feed&quot;);\n    const textbox = document.getElementById(&quot;output_box&quot;);\n\n\n    if (!video) {\n        console.log(&quot;Required elements not found.&quot;);\n        return;\n    }\n\n    const boundingBox = video.getBoundingClientRect();\n\n    const outputBox = document.querySelector(&quot;#real_box textarea&quot;)\n\n    video.addEventListener(&quot;click&quot;, function handleClick(event) {\n        console.log(&quot;Got click: &quot;, event);\n        const relativeX = event.clientX - boundingBox.left;\n        const relativeY = event.clientY - boundingBox.top;\n\n        const message = `Clicked at X: ${Math.round(relativeX)} Y: ${Math.round(relativeY)}`;\n        console.log(message);\n\n        outputBox.value = message;\n        let event2 = new Event(&quot;input&quot;)\n        outputBox.dispatchEvent(event2);\n\n    \n\n\n    }, false);\n\n    console.log(&quot;AFTER&quot;);\n\n    return 'Animation created';\n}\n&quot;&quot;&quot;\n\n\ndef handle_click(x=0, y=0):\n    return f&quot;Received from JS: X={x}, Y={y}&quot;\n\n\ndef handle_textbox_change(text):\n    return &quot;Received from JS: &quot; + text\n\n\nwith gr.Blocks(js=script) as demo:\n    gr.Markdown(&quot;Click on the image to trigger a Python function&quot;)\n    output = gr.Textbox(label=&quot;Response from Python&quot;, elem_id=&quot;real_box&quot;)\n\n    textbox = gr.Textbox(elem_id=&quot;output_box&quot;)\n    textbox.change(fn=handle_textbox_change, inputs=textbox, outputs=output)\n\n    # Add a visible image to click on\n    img = gr.Image(value=&quot;test_images/frog.jpg&quot;, elem_id=&quot;video_feed&quot;)\n\ndemo.launch()\n</code></pre>\n<p>Basically involves setting a textbox's value based on your data (you can set the textbox <code>visible</code> value to False too I believe).\nObviously don't use this for any sensitive information, but it gets the job done quickly.</p>\n",
    "link": "https://stackoverflow.com/questions/77586262/using-custom-js-event-handler-inside-gradio"
  },
  {
    "question": "gradio voice interface not launching from command line",
    "answer": "<p>The resolution turned out to be related to the use of Git Bash shell. Switching to a windows command shell solved the problem.</p>\n",
    "link": "https://stackoverflow.com/questions/79546935/gradio-voice-interface-not-launching-from-command-line"
  },
  {
    "question": "sqlite table does not exist within gradio blocks or GradioUI even after creating said table",
    "answer": "<p>I used <code>sqlite:///:localhost:</code> and it solved. Thanks to @rasjani for the suggestion!</p>\n",
    "link": "https://stackoverflow.com/questions/79548083/sqlite-table-does-not-exist-within-gradio-blocks-or-gradioui-even-after-creating"
  },
  {
    "question": "FastAPI uvicorn starrlette gradio package errors",
    "answer": "<p>I was be able to solve this by changing starlette version.<br />\nI had:</p>\n<ul>\n<li><p><code>fastapi==0.101.1</code></p>\n</li>\n<li><p><code>starlette==0.46.0</code></p>\n</li>\n</ul>\n<p>It turns out they were <strong>incompatible</strong>.</p>\n<p>After changing  to</p>\n<ul>\n<li><p><code>fastapi==0.101.1</code></p>\n</li>\n<li><p><code>starlette==0.27.0</code></p>\n</li>\n</ul>\n<p>everything works fine.</p>\n",
    "link": "https://stackoverflow.com/questions/78732237/fastapi-uvicorn-starrlette-gradio-package-errors"
  },
  {
    "question": "Develop a txt2img API for custom frontend",
    "answer": "<p>If you are using Windows,</p>\n<p>you can modify webui-user.bat and add &quot;set COMMANDLINE_ARGS=--api&quot;,</p>\n<p>send a post request url:{webui_uri}/sdapi/v1/txt2img,</p>\n<p>the body content can refer to this URL <a href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/3734\" rel=\"nofollow noreferrer\">https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/3734</a>,</p>\n<p>the response can be taken from the key &quot;images&quot;,</p>\n<p>there will be a picture, hope it can help you</p>\n",
    "link": "https://stackoverflow.com/questions/77015478/develop-a-txt2img-api-for-custom-frontend"
  },
  {
    "question": "How do you apply session state to Gradio&#39;s ChatInterface?",
    "answer": "<p>You need to pass in the chain via <a href=\"https://www.gradio.app/guides/interface-state\" rel=\"nofollow noreferrer\">session state</a> for it to not be global.</p>\n<pre class=\"lang-py prettyprint-override\"><code>def predict(message, history, chain):\n    ...\n    gpt_response = chain({&quot;question&quot;: message})\n    return gpt_response['answer'], chain\n\nwith gr.Block() as app:\n    chain_state = gr.State(\n         load_chain\n    ) \n    chatbot = gr.ChatInterface(\n        fn=predict,\n        additional_inputs=[chain_state],\n        additional_outputs=[chain_state],\n        title=&quot;Chatbot&quot;\n    )\n\napp.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/77279657/how-do-you-apply-session-state-to-gradios-chatinterface"
  },
  {
    "question": "How can I call with Postman a RESTful API deployed with Gradio?",
    "answer": "<p>I found the answer on <a href=\"https://github.com/aiplaybookin/gradio-demo\" rel=\"nofollow noreferrer\">https://github.com/aiplaybookin/gradio-demo</a>:</p>\n<blockquote>\n<p>Use¬†<a href=\"https://hoppscotch.io/\" rel=\"nofollow noreferrer\">https://hoppscotch.io</a>¬†or¬†<a href=\"https://www.postman.com/\" rel=\"nofollow noreferrer\">https://www.postman.com/</a></p>\n<ul>\n<li><p>As the API is POST select POST</p>\n</li>\n<li><p>Paste the full URL¬†<a href=\"https://locahost:7861/api/predict\" rel=\"nofollow noreferrer\">https://locahost:7861/api/predict</a></p>\n</li>\n<li><p>Go to Body and Set the content type to¬†<code>application/json</code></p>\n</li>\n<li><p>Paste the input Payload in the body &amp; convert your image to base64 using online tool (<a href=\"https://www.base64-image.de/\" rel=\"nofollow noreferrer\">https://www.base64-image.de/</a>) and paste it as value.</p>\n</li>\n</ul>\n</blockquote>\n<p>In my case:</p>\n<p><a href=\"https://i.sstatic.net/DGuuN.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/DGuuN.png\" alt=\"enter image description here\" /></a></p>\n<p>JSON payload:</p>\n<pre><code>{&quot;data&quot;: [&quot;test&quot;]}\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/77342593/how-can-i-call-with-postman-a-restful-api-deployed-with-gradio"
  },
  {
    "question": "How to display text and plotly chart with gradio in the same output box",
    "answer": "<p>This is the closest I could find, it's only available in the chatbot object.  If you are doing a lot of customization, it might not work, but it's worth a look:</p>\n<p><a href=\"https://www.gradio.app/docs/gradio/chatbot\" rel=\"nofollow noreferrer\">https://www.gradio.app/docs/gradio/chatbot</a></p>\n",
    "link": "https://stackoverflow.com/questions/78105758/how-to-display-text-and-plotly-chart-with-gradio-in-the-same-output-box"
  },
  {
    "question": "Drawing Bounding Boxes with Gradio",
    "answer": "<p>Currently, drawing Bounding Boxes directly in gradio is not possible. You have to render them yourself onto the image in your python code. The drawback of this is that the user can not adjust the boxes on the UI.</p>\n<p>Note, there is a <a href=\"https://github.com/gradio-app/gradio/pull/3220\" rel=\"nofollow noreferrer\">recent PR</a> that has been declined. There also is a <a href=\"https://github.com/gradio-app/gradio/issues/1836\" rel=\"nofollow noreferrer\">possible workaround</a> by obtaining the bounding boxes through the cropped image.</p>\n",
    "link": "https://stackoverflow.com/questions/75926283/drawing-bounding-boxes-with-gradio"
  },
  {
    "question": "How to Implement Page Separation in Gradio?",
    "answer": "<p>Gradio doesn't have pages but you can use Tabs to implement a similar functionality. Modifying your code slightly and using gr.TabbedInterface()-</p>\n<pre><code>    import gradio as gr\n\n# Code for Task 1\ndef task1(input_text):\n    # Task 1 logic\n    return &quot;Task 1 Result: &quot; + input_text\n\n# Code for Task 2\ndef task2(input_image):\n    # Task 2 logic\n    return &quot;Task 2 Result&quot;\n\n# interface one\niface1 = gr.Interface(\n    fn=task1,\n    inputs=&quot;text&quot;,\n    outputs=&quot;text&quot;,\n    title=&quot;Multi-Page Interface&quot;\n)\n# interface two\niface2 = gr.Interface(\n    fn=task2,\n    inputs=&quot;image&quot;,\n    outputs=&quot;text&quot;,\n    title=&quot;Multi-Page Interface&quot;\n)\n\ndemo = gr.TabbedInterface([iface1, iface2], [&quot;Text-to-text&quot;, &quot;image-to-text&quot;])\n\n# Run the interface\ndemo.launch(share=True)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76872565/how-to-implement-page-separation-in-gradio"
  },
  {
    "question": "RuntimeError: &quot;Unused kwargs&quot; and &quot;frozenset object has no attribute discard&quot; with BitsAndBytes bf16 Quantized Model in Hugging Face Gradio App",
    "answer": "<p>I'm using a Dell Laptop with an Intel GPU and so I could not use the &quot;default&quot; version of the <code>bitsandbytes</code> Python library which supports CUDA-based GPUs.</p>\n<p>As explained in the Hugging Face documentation of the library the <a href=\"https://huggingface.co/docs/bitsandbytes/en/installation#multi-backend\" rel=\"nofollow noreferrer\">Multi-backend Support (Alpha Release)</a> has to be used.</p>\n<p>As you I also installed the library by reading the <a href=\"https://huggingface.co/docs/bitsandbytes/en/installation#multi-backend-pip\" rel=\"nofollow noreferrer\">Pre-built Wheel Installation (recommended)</a> section.</p>\n<p>After that I encountered the same error as you, that's to say <code>AttributeError: 'frozenset' object has no attribute 'discard'</code>.</p>\n<p>After reading the source code of the library we see that the function which returns a <code>FrozenSet</code> is the <code>get_available_devices()</code> function (see <a href=\"https://github.com/huggingface/transformers/blob/v4.48.1/src/transformers/integrations/bitsandbytes.py#L491\" rel=\"nofollow noreferrer\">https://github.com/huggingface/transformers/blob/v4.48.1/src/transformers/integrations/bitsandbytes.py#L491</a>) and that when the error is returned it's associated to the <code>is_ipex_available()</code> returning <code>True</code>.</p>\n<p>Digging a little more we understand that the <code>is_ipex_available()</code> function returns <code>True</code> when the <a href=\"https://intel.github.io/intel-extension-for-pytorch/\" rel=\"nofollow noreferrer\">Intel Extension for PyTorch</a> is available.</p>\n<p>So you have to install this extension and the error should be solved. In fact if you read the <a href=\"https://huggingface.co/docs/bitsandbytes/en/installation?backend=Intel+CPU+%2B+GPU#multi-backend-compile\" rel=\"nofollow noreferrer\">Compile from Source</a> section specific to Intel GPUs in the documentation you'll see a <code>pip install intel_extension_for_pytorch</code> instruction.</p>\n<p><strong>Fix with Poetry</strong></p>\n<p>In my case I used <a href=\"https://python-poetry.org/\" rel=\"nofollow noreferrer\">Poetry</a> 2.x, here are the main configuration properties I used to fix the problem.</p>\n<pre><code># pyproject.toml\n\n...\n\n[[tool.poetry.source]]\nname = &quot;intel-extension-for-pytorch&quot;\nurl = &quot;https://pytorch-extension.intel.com/release-whl/stable/cpu/us/&quot;\npriority = &quot;supplemental&quot;\n\n...\n\n[tool.poetry.group.main.dependencies]\naccelerate = &quot;^1.3&quot;\nbitsandbytes = {url = &quot;https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_multi-backend-refactor/bitsandbytes-0.44.1.dev0-py3-none-manylinux_2_24_x86_64.whl&quot;}\nintel-extension-for-pytorch = {version = &quot;^2.5.0+cpu&quot;, source = &quot;intel-extension-for-pytorch&quot;}\ntorch = {version = &quot;^2.5.1&quot;}\ntransformers = {extras = [&quot;pytorch&quot;], version = &quot;^4.48.1&quot;}\n...\n</code></pre>\n<p>Those instructions are almost the same as the ones documented on the official site <a href=\"https://pytorch-extension.intel.com/installation?platform=cpu&amp;version=v2.5.0%2Bcpu&amp;os=linux%2Fwsl2&amp;package=pip\" rel=\"nofollow noreferrer\">https://pytorch-extension.intel.com/installation?platform=cpu&amp;version=v2.5.0%2Bcpu&amp;os=linux%2Fwsl2&amp;package=pip</a></p>\n<p>Hope this helps.</p>\n<p>Baptiste</p>\n",
    "link": "https://stackoverflow.com/questions/79175246/runtimeerror-unused-kwargs-and-frozenset-object-has-no-attribute-discard-wi"
  },
  {
    "question": "How to show dedicated progress bar in each tab in a Gradio app?",
    "answer": "<p>You need to manually pass the progress bar and maintain tabs differently. Also need to use callback_on_step_end with manual ones is needed.</p>\n<p>Try this code:</p>\n<pre><code>import spaces\nimport torch\nimport random\nimport numpy as np\nfrom inspect import signature\nfrom diffusers import (\n    FluxPipeline,\n    StableDiffusion3Pipeline,\n    PixArtSigmaPipeline,\n    SanaPipeline,\n    AuraFlowPipeline,\n    Kandinsky3Pipeline,\n    HunyuanDiTPipeline,\n    LuminaText2ImgPipeline,AutoPipelineForText2Image\n)\nimport gradio as gr\nfrom diffusers.pipelines.pipeline_utils import DiffusionPipeline\n\nMAX_SEED = np.iinfo(np.int32).max\nMAX_IMAGE_SIZE = 1024\n\nclass ProgressPipeline(DiffusionPipeline):\n    def __init__(self, original_pipeline):\n        super().__init__()\n        self.original_pipeline = original_pipeline\n        # Register all components from the original pipeline\n        for attr_name, attr_value in vars(original_pipeline).items():\n            setattr(self, attr_name, attr_value)\n    \n    @torch.no_grad()\n    def __call__(\n        self,\n        prompt,\n        num_inference_steps=30,\n        generator=None,\n        guidance_scale=7.5,\n        callback=None,\n        callback_steps=1,\n        **kwargs\n    ):\n        # Initialize the progress tracking\n        self._num_inference_steps = num_inference_steps\n        self._step = 0\n        \n        def progress_callback(step_index, timestep, callback_kwargs):\n            if callback and step_index % callback_steps == 0:\n                # Pass self (the pipeline) to the callback\n                callback(self, step_index, timestep, callback_kwargs)\n            return callback_kwargs\n        \n        # Monkey patch the original pipeline's progress tracking\n        original_step = self.original_pipeline.scheduler.step\n        def wrapped_step(*args, **kwargs):\n            self._step += 1\n            progress_callback(self._step, None, {})\n            return original_step(*args, **kwargs)\n        \n        self.original_pipeline.scheduler.step = wrapped_step\n        \n        try:\n            # Call the original pipeline\n            result = self.original_pipeline(\n                prompt=prompt,\n                num_inference_steps=num_inference_steps,\n                generator=generator,\n                guidance_scale=guidance_scale,\n                **kwargs\n            )\n            \n            return result\n        finally:\n            # Restore the original step function\n            self.original_pipeline.scheduler.step = original_step\n\ncache_dir = '/workspace/hf_cache'\n\nMODEL_CONFIGS = {\n        &quot;FLUX&quot;: {\n        &quot;repo_id&quot;: &quot;black-forest-labs/FLUX.1-dev&quot;,\n        &quot;pipeline_class&quot;: FluxPipeline,\n    },\n    &quot;Stable Diffusion 3.5&quot;: {\n        &quot;repo_id&quot;: &quot;stabilityai/stable-diffusion-3.5-large&quot;,\n        &quot;pipeline_class&quot;: StableDiffusion3Pipeline,\n         \n    },\n    &quot;PixArt&quot;: {\n        &quot;repo_id&quot;: &quot;PixArt-alpha/PixArt-Sigma-XL-2-1024-MS&quot;,\n        &quot;pipeline_class&quot;: PixArtSigmaPipeline,\n        \n    },\n    &quot;SANA&quot;: {\n        &quot;repo_id&quot;: &quot;Efficient-Large-Model/Sana_1600M_1024px_BF16_diffusers&quot;,\n        &quot;pipeline_class&quot;: SanaPipeline,\n         \n    },\n    &quot;AuraFlow&quot;: {\n        &quot;repo_id&quot;: &quot;fal/AuraFlow&quot;,\n        &quot;pipeline_class&quot;: AuraFlowPipeline,\n         \n    },\n    &quot;Kandinsky&quot;: {\n        &quot;repo_id&quot;: &quot;kandinsky-community/kandinsky-3&quot;,\n        &quot;pipeline_class&quot;: Kandinsky3Pipeline,\n        \n    },\n    &quot;Hunyuan&quot;: {\n        &quot;repo_id&quot;: &quot;Tencent-Hunyuan/HunyuanDiT-Diffusers&quot;,\n        &quot;pipeline_class&quot;: HunyuanDiTPipeline,\n         \n    },\n    &quot;Lumina&quot;: {\n        &quot;repo_id&quot;: &quot;Alpha-VLLM/Lumina-Next-SFT-diffusers&quot;,\n        &quot;pipeline_class&quot;: LuminaText2ImgPipeline,\n         \n    }\n}\n\ndef generate_image_with_progress(model_name,pipe, prompt, num_steps, guidance_scale=3.5, seed=None,negative_prompt=None,  randomize_seed=None, width=1024, height=1024, num_inference_steps=40,  progress=gr.Progress(track_tqdm=True)):\n    generator = None\n    if randomize_seed:\n        seed = random.randint(0, MAX_SEED)\n    if seed is not None:\n        generator = torch.Generator(&quot;cuda&quot;).manual_seed(seed)\n    else:\n        generator = torch.Generator(&quot;cuda&quot;)\n\n    def callback(pipe, step_index, timestep, callback_kwargs):\n        print(f&quot; callback =&gt; {step_index}, {timestep}&quot;)\n        if step_index is None:\n            step_index = 0\n        cur_prg = step_index / num_steps\n        progress(cur_prg, desc=f&quot;Step {step_index}/{num_steps}&quot;)\n        return callback_kwargs\n    print(f&quot;START GENR &quot;)\n    # Get the signature of the pipe\n    pipe_signature = signature(pipe)\n    \n    # Check for the presence of &quot;guidance_scale&quot; and &quot;callback_on_step_end&quot; in the signature\n    has_guidance_scale = &quot;guidance_scale&quot; in pipe_signature.parameters\n    has_callback_on_step_end = &quot;callback_on_step_end&quot; in pipe_signature.parameters\n    \n    # Define common arguments\n    common_args = {\n        &quot;prompt&quot;: prompt,\n        &quot;num_inference_steps&quot;: num_steps,\n        &quot;negative_prompt&quot;: negative_prompt,\n        &quot;width&quot;: width,\n        &quot;height&quot;: height,\n        &quot;generator&quot;: generator,\n    }\n    \n    if has_guidance_scale:\n        common_args[&quot;guidance_scale&quot;] = guidance_scale\n    \n    if has_callback_on_step_end:\n        print(&quot;has callback_on_step_end and&quot;, &quot;has guidance_scale&quot; if has_guidance_scale else &quot;NO guidance_scale&quot;)\n        common_args[&quot;callback_on_step_end&quot;] = callback\n    else:\n        print(&quot;NO callback_on_step_end and&quot;, &quot;has guidance_scale&quot; if has_guidance_scale else &quot;NO guidance_scale&quot;)\n        common_args[&quot;callback&quot;] = callback\n        common_args[&quot;callback_steps&quot;] = 1\n    \n    # Generate image\n    image = pipe(**common_args).images[0]\n\n    return seed, image\n\n@spaces.GPU(duration=170)\ndef create_pipeline_logic(prompt_text, model_name, negative_prompt=&quot;&quot;,  seed=42, randomize_seed=False, width=1024, height=1024, guidance_scale=4.5, num_inference_steps=40,):\n    print(f&quot;starting {model_name}&quot;)\n    progress = gr.Progress(track_tqdm=True)\n    config = MODEL_CONFIGS[model_name]\n    pipe_class = config[&quot;pipeline_class&quot;]\n    pipe = None\n    b_pipe = AutoPipelineForText2Image.from_pretrained(\n        config[&quot;repo_id&quot;],\n        #variant=&quot;fp16&quot;,\n        #cache_dir=config[&quot;cache_dir&quot;],\n        torch_dtype=torch.bfloat16\n    ).to(&quot;cuda&quot;)\n    pipe_signature = signature(b_pipe)\n    # Check for the presence of &quot;callback_on_step_end&quot; in the signature\n    has_callback_on_step_end = &quot;callback_on_step_end&quot; in pipe_signature.parameters\n    if not has_callback_on_step_end:\n        pipe = ProgressPipeline(b_pipe)\n        print(&quot;ProgressPipeline specal&quot;)\n    else:\n        pipe = b_pipe\n        \n    gen_seed,image = generate_image_with_progress(\n        model_name,pipe, prompt_text, num_steps=num_inference_steps, guidance_scale=guidance_scale, seed=seed,negative_prompt = negative_prompt,  randomize_seed = randomize_seed, width = width, height = height, progress=progress\n    )\n    return f&quot;Seed: {gen_seed}&quot;, image\n\ndef main():\n    with gr.Blocks() as app:\n        gr.Markdown(&quot;# Dynamic Multiple Model Image Generation&quot;)\n\n        prompt_text = gr.Textbox(label=&quot;Enter prompt&quot;)\n\n        with gr.Accordion(&quot;Advanced Settings&quot;, open=False):\n            negative_prompt = gr.Text(\n                label=&quot;Negative prompt&quot;,\n                max_lines=1,\n                placeholder=&quot;Enter a negative prompt&quot;,\n            )\n\n            seed = gr.Slider(\n                label=&quot;Seed&quot;,\n                minimum=0,\n                maximum=MAX_SEED,\n                step=100,\n                value=0,\n            )\n\n            randomize_seed = gr.Checkbox(label=&quot;Randomize seed&quot;, value=True)\n\n            with gr.Row():\n                width = gr.Slider(\n                    label=&quot;Width&quot;,\n                    minimum=512,\n                    maximum=MAX_IMAGE_SIZE,\n                    step=32,\n                    value=1024,\n                )\n                height = gr.Slider(\n                    label=&quot;Height&quot;,\n                    minimum=512,\n                    maximum=MAX_IMAGE_SIZE,\n                    step=32,\n                    value=1024,\n                )\n\n            with gr.Row():\n                guidance_scale = gr.Slider(\n                    label=&quot;Guidance scale&quot;,\n                    minimum=0.0,\n                    maximum=7.5,\n                    step=0.1,\n                    value=4.5,\n                )\n                num_inference_steps = gr.Slider(\n                    label=&quot;Number of inference steps&quot;,\n                    minimum=1,\n                    maximum=50,\n                    step=1,\n                    value=40,\n                )\n\n        for model_name, config in MODEL_CONFIGS.items():\n            with gr.Tab(model_name):\n                button = gr.Button(f&quot;Run {model_name}&quot;)\n                output = gr.Textbox(label=&quot;Status&quot;)\n                img = gr.Image(label=model_name, height=300)\n\n                button.click(fn=create_pipeline_logic, inputs=[prompt_text, gr.Text(value= model_name,visible=False), negative_prompt,\n            seed,\n            randomize_seed,\n            width,\n            height,\n            guidance_scale,\n            num_inference_steps], outputs=[output, img])\n\n    app.launch()\n\n\nif __name__ == &quot;__main__&quot;:\n    main()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/79321289/how-to-show-dedicated-progress-bar-in-each-tab-in-a-gradio-app"
  },
  {
    "question": "How to dynamic serve gradio content in FastAPI on runtime?",
    "answer": "<p>You can't render HTML from fastapi more than once in a HTTP connection session, as it's limited by a HTTP protocol, but you can return JS code that will dynamically update contents of a page on your web browser.</p>\n<p>Looks like you need a <a href=\"https://fastapi.tiangolo.com/advanced/websockets/\" rel=\"nofollow noreferrer\">fastapi.WebSocket</a> or <a href=\"https://python-socketio.readthedocs.io/en/stable/intro.html#server-examples\" rel=\"nofollow noreferrer\">socketio</a> app (you can mount it into a FastAPI app) or just polling on frontend side. There are examples of JS code for frontend in a docs. Frontend connects to backend and gathers information in runtime (as you set up on backend). Also you can use <a href=\"https://fastapi.tiangolo.com/advanced/custom-response/#streamingresponse\" rel=\"nofollow noreferrer\">fastapi.StreamingResponse</a> as a one-way connection channel, but you also need to return JS code that will read blocks of HTTP page body as stream.</p>\n",
    "link": "https://stackoverflow.com/questions/79280213/how-to-dynamic-serve-gradio-content-in-fastapi-on-runtime"
  },
  {
    "question": "gradio HTML component with &lt;script&gt; in head of gr.Block not working",
    "answer": "<p>I never used Gradio before, but after looking a bit at the docs I found out a potentially good solution, although with a slightly different approach. The steps are:</p>\n<ol>\n<li>Set as <code>head</code> the definition of the function that will be run when the first <code>div</code> is clicked.</li>\n<li>Define the HTML elements setting the <code>onclick</code> attribute to the first <code>div</code>, which will be calling the function defined in step 1.</li>\n</ol>\n<p>After running this snippet, it worked for me:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\n\nhead = &quot;&quot;&quot;\n&lt;script&gt;\n  function clickHandler() {\n    console.log(&quot;First div clicked!&quot;);\n    var secondDiv = document.getElementById(&quot;second_div&quot;);\n    secondDiv.style.display = &quot;block&quot;;\n  }\n&lt;/script&gt;\n&quot;&quot;&quot;\n\nwith gr.Blocks(head=head) as demo:\n    gr.HTML(\n        &quot;&quot;&quot;\n        &lt;div id=&quot;first_div&quot; onclick=&quot;clickHandler()&quot; style=&quot;cursor:pointer; background-color:#eee; padding:10px; margin-bottom:10px;&quot;&gt;\n            Click Me!\n        &lt;/div&gt;\n        &quot;&quot;&quot;\n    )\n    gr.HTML(\n        &quot;&quot;&quot;\n        &lt;div id=&quot;second_div&quot; style=&quot;display:none; background-color:#ddd; padding:10px;&quot;&gt;\n            You clicked, I am visible!\n        &lt;/div&gt;\n        &quot;&quot;&quot;\n    )\n\ndemo.launch()\n</code></pre>\n<p>Hope it works for you, too!</p>\n",
    "link": "https://stackoverflow.com/questions/79271492/gradio-html-component-with-script-in-head-of-gr-block-not-working"
  },
  {
    "question": "Gradio : Login System. How to get a fully functional Login system on Gradio?",
    "answer": "<p>After weeks of reading through the documents I have finally figured it out.</p>\n<p>You can do it with FastAPI + Gradio</p>\n<p>Essentially you store all tokens you want as cookies (preferably HTTPOnly cookies managed by fastapi service)</p>\n<p>How I implement this is, whenever a user calls any gradio button / object that needs be verified, it sends a JS request to set, delete or update cookies cookies, example:</p>\n<pre><code>import gradio as gr\n\ndef doNothing():\n    pass\n\n\ndef doSomething(request: gr.Request):\n    \n    # Do you application code here\n\n    # Print Cookies using this:\n    # Over here in the headers you will find all the cookies\n    print(request.request.__dict__)\n\n    return ''\n    \nwith gr.Blocks() as sample:\n\n    button = gr.Button()\n    \n    # This is done just to avoid a warning from gradio\n    hidden = gr.Textbox(visible=False)\n\n    button.click(\n        fn=doNothing,\n        outputs=sample,\n        js=&quot;&quot;&quot;\n            async () =&gt; {\n                let response = await fetch('/healthCheck', {\n                    method: 'GET',\n                    credentials: 'include'  // Include cookies in the request\n                });\n\n                // Use the Response Status to figure if a redirect is needed\n                if (response.status != 200) {\n                    window.location.href = '/login';\n                }\n            }\n        &quot;&quot;&quot;\n    ).then(\n        fn=doSomething,  # This will execute after the JS completes\n    )\n</code></pre>\n<p>Your <code>healthCheck</code> fastapi endpoint is responsible for maintaining and updating cookies, you can use Session Middleware if you need through Starlette</p>\n<p>To extend this to a proper login functionality follow this guide:\n<a href=\"https://github.com/gradio-app/gradio/issues/7005\" rel=\"nofollow noreferrer\">https://github.com/gradio-app/gradio/issues/7005</a></p>\n<p>Please ensure you are setting / deleting cookies wherever needed\nand the JS call is called whenever the browser cookies need to be updated</p>\n<p>I prefer not to use RedirectResponses, since they only work when the browser is making the request directly and not if a specific event listener's function is making that</p>\n<p>However, for an easier implementation you can only follow the above guide and use Session Middleware dict for all your tokens - I prefer the browser cookie method since its more customizable and not just limited to the SessionMiddleware and I can make it secure by updating the config</p>\n",
    "link": "https://stackoverflow.com/questions/77082602/gradio-login-system-how-to-get-a-fully-functional-login-system-on-gradio"
  },
  {
    "question": "How to retrieve user&#39;s username after authenticating in Gradio",
    "answer": "<p>In any of your functions, you can get the logged in username as :</p>\n<pre><code>def print_user(request: gr.Request):\n        print({request.username}) \n</code></pre>\n<p>As mentioned in the above suggested gradio links, <code>gr.Request</code> can be used in any function within gradio app and request related information can be retrieved.</p>\n",
    "link": "https://stackoverflow.com/questions/77494902/how-to-retrieve-users-username-after-authenticating-in-gradio"
  },
  {
    "question": "How can I update display of chat history upon page refresh?",
    "answer": "<p>The solution is to turn <code>formatted_history</code> into a state. In order to do this is to use <code>demo.load</code> at your code and set as output the <code>chatbot</code> element.</p>\n<p>The final example is:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import sqlite3\nimport gradio as gr\nimport time\n\nformatted_history = []\nsqlite = None\n\n\ndef loadHistoryFromDB():\n    &quot;&quot;&quot;Fetch the latest 10 messages from the database and populate `formatted_history`.&quot;&quot;&quot;\n    global sqlite, formatted_history\n\n    sql = &quot;SELECT role, message FROM chat_history ORDER BY created_at_unix ASC LIMIT 10&quot;\n    cur = sqlite.cursor()\n    cur.execute(sql)\n    rows = cur.fetchall()\n    for row in rows:\n        formatted_history.append({\n            'role': row[0],\n            'content': row[1]\n        })\n\n\ndef chatHandler(message, history):\n    global sqlite,formatted_history\n    &quot;&quot;&quot;Handle new messages and update chat history in the database and UI.&quot;&quot;&quot;\n    sql = &quot;INSERT INTO chat_history (role, message, created_at_unix) VALUES (?, ?, ?)&quot;\n    current_unix_time = int(time.time())  # Get the current Unix timestamp\n\n    # Save user's message to the database\n    sqlite.execute(sql, ('user', message, current_unix_time))\n    formatted_history.append({&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:message})\n    # Generate the assistant's response\n    response = f&quot;Hello {message}&quot;\n\n    # Save assistant's response to the database\n    sqlite.execute(sql, ('assistant', response, int(time.time())))\n    formatted_history.append({&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:response})\n    sqlite.commit()\n\n    yield response\n\nif __name__ == &quot;__main__&quot;:\n    # Initialize the database connection\n    sqlite = sqlite3.connect(&quot;chat_history.db&quot;, check_same_thread=False)\n\n    # Load initial chat history\n    loadHistoryFromDB()\n\n    # Set up the Gradio interface\n    with gr.Blocks() as demo:\n        chatbot = gr.Chatbot(type=&quot;messages&quot;, value=formatted_history)\n        chat = gr.ChatInterface(fn=chatHandler, type=&quot;messages&quot;, chatbot=chatbot)\n        demo.load(lambda :formatted_history,None,chatbot)\n\n    # Launch the application\n    demo.launch()\n</code></pre>\n<p>First and foremost pay attention at:</p>\n<pre class=\"lang-py prettyprint-override\"><code>    with gr.Blocks() as demo:\n        chatbot = gr.Chatbot(type=&quot;messages&quot;, value=formatted_history)\n        chat = gr.ChatInterface(fn=chatHandler, type=&quot;messages&quot;, chatbot=chatbot)\n        demo.load(lambda :formatted_history,None,chatbot)\n</code></pre>\n<p>As explained above, I set the chatbot as output of the whatever I store upon <code>formatted_history</code>. Another way you should pay attention is in the function <code>chatHandler</code> In that we append the nessesary messages into <code>formatted_history</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>def chatHandler(message, history):\n    global sqlite,formatted_history\n    &quot;&quot;&quot;Handle new messages and update chat history in the database and UI.&quot;&quot;&quot;\n    sql = &quot;INSERT INTO chat_history (role, message, created_at_unix) VALUES (?, ?, ?)&quot;\n    current_unix_time = int(time.time())  # Get the current Unix timestamp\n\n    sqlite.execute(sql, ('user', message, current_unix_time))\n    \n    # Append Value upon `formatted_history` in order to update the state\n    formatted_history.append({&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:message})\n\n    # Generate the assistant's response\n    response = f&quot;Hello {message}&quot;\n\n    sqlite.execute(sql, ('assistant', response, int(time.time())))\n\n    # Append Value upon `formatted_history` in order to update the state\n    formatted_history.append({&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:response})\n    sqlite.commit()\n\n    yield response\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/79210603/how-can-i-update-display-of-chat-history-upon-page-refresh"
  },
  {
    "question": "How to hide/disable processing time message?",
    "answer": "<p>Through trial and error I've found that this works:</p>\n<pre><code>gr.Blocks(css=&quot;.progress-text { display: none !important; })&quot;\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/79213426/how-to-hide-disable-processing-time-message"
  },
  {
    "question": "How to add heading or text before input/output in gradio?",
    "answer": "<p>The base gradio <a href=\"https://www.gradio.app/docs/interface\" rel=\"nofollow noreferrer\">&quot;Interface&quot;</a> class has parameters (title, description &amp; article) that take strings and are rendered as helpful text for the app.  These are the simplest ways to provide some context and instruction.</p>\n<p>For example:</p>\n<pre><code>title = &quot;Awesome ML App&quot;\ndesc = &quot;This is an awesome ML App.  I'm really excited to show you&quot;\nlong_desc = &quot;Let me tell you ALL about this awesome ML App&quot;\niface = gr.Interface(fn=classify_image, inputs=image, outputs=label, theme=gr.themes.Glass(), \n                examples=[example1, ref_example, example2], title=title, \n                description=desc, article=long_desc)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76901604/how-to-add-heading-or-text-before-input-output-in-gradio"
  },
  {
    "question": "how to dynamically vertically scale layout with gr.Row() and multiple gr.Column() in Gradio",
    "answer": "<p>Here is example of code that works. Found the solution at <a href=\"https://stackoverflow.com/questions/78536986/a-chat-with-gradio-how-to-modify-its-screen-appearance\">1</a></p>\n<pre><code>import requests\nimport gradio as gr\nimport json\n\ndef chat_response(message, history, response_limit):\n    return f&quot;You wrote: {message} and asked {response_limit}&quot;\n\ncss = &quot;&quot;&quot;\n#chatbot {\n    flex-grow: 1 !important;\n    overflow: auto !important;\n}\n&quot;&quot;&quot;\n\nwith gr.Blocks(css=css) as demo:\n    gr.Markdown(&quot;# Data Query!&quot;)\n    with gr.Row():\n        with gr.Column(scale=3):\n            response_limit = gr.Number(label=&quot;Response Limit&quot;, value=10, interactive=True)\n        with gr.Column(scale=7):\n            chat = gr.ChatInterface(\n                fn=chat_response,\n                chatbot=gr.Chatbot(elem_id=&quot;chatbot&quot;,\n                                    render=False),\n                additional_inputs=[response_limit]\n            )\ndemo.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/79157487/how-to-dynamically-vertically-scale-layout-with-gr-row-and-multiple-gr-column"
  },
  {
    "question": "Gradio 5.0.2 Image: how to dispatch the start_recording event",
    "answer": "<p>I have faced this problem. Actually, basic <code>Events</code> (<code>from gradio.events import Events, EventListener</code>) class does not have your defined event <code>start_recording</code>, so you need to create a child class like <code>CustomEvents</code> to add your new event.</p>\n<pre><code>class CustomEvents(Events):\n    calibrated = EventListener(\n        &quot;start_recording&quot;,\n        doc=&quot;...&quot;,\n    )\n</code></pre>\n<p>then in your component's class, use <code>CustomEvents</code> instead.</p>\n<pre><code>class MyImage(StreamingInput, Component):\n\n    EVENTS = [\n        CustomEvents.clear,\n        CustomEvents.change,\n        CustomEvents.stream,\n        CustomEvents.select,\n        CustomEvents.upload,\n        CustomEvents.input,\n        CustomEvents.start_recording, # Added\n    ]\n</code></pre>\n<p>After that, you need to <code>pip install -e .</code> so that your package is updated, and you can import to run it. The newly added event will be generated a function in the <code>.pyi</code> file, hence your custom element can be use it.</p>\n",
    "link": "https://stackoverflow.com/questions/79092005/gradio-5-0-2-image-how-to-dispatch-the-start-recording-event"
  },
  {
    "question": "how to add images in the markdown html gradio",
    "answer": "<p>i have explored and found that we need to modify the code to add images in html</p>\n<pre><code>import gradio as gr\n\nwith gr.Blocks() as demo:\n    # add file before your image file path\n    gr.HTML(&quot;&lt;img src='file/image.png' alt='image One'&gt;&quot;)\n\n# add allowed_path  in launch\ndemo.launch(allowed_paths=[&quot;.&quot;])\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/79116936/how-to-add-images-in-the-markdown-html-gradio"
  },
  {
    "question": "Is there a way to make the rows of a gradio dataframe clickable?",
    "answer": "<p>yep! You can add a click listener to the table and get the row value from the event</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\nimport pandas as pd\nimport numpy as np\n\n\ndef generate_random_dataframe():\n    # Generate a random DataFrame\n    df = pd.DataFrame(np.random.rand(10, 5), columns=list('ABCDE'))\n    return df\n\n\ndef df_select_callback(df: pd.DataFrame,  evt: gr.SelectData):\n    return sum(evt.row_value)\n\n\nwith gr.Blocks() as demo:\n    generate_button = gr.Button(&quot;Generate Random DataFrame&quot;)\n\n    output_df = gr.DataFrame()\n    sum_textarea = gr.Textbox(&quot;&quot;)\n    generate_button.click(fn=generate_random_dataframe,\n                          inputs=[], outputs=output_df)\n\n    output_df.select(df_select_callback,\n                     inputs=[output_df],\n                     outputs=[sum_textarea])\n\ndemo.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/78660517/is-there-a-way-to-make-the-rows-of-a-gradio-dataframe-clickable"
  },
  {
    "question": "gradio how to hide a webcam interface",
    "answer": "<p>The problem is that you're passing the entire gr.Interface object (webcam) as an input or output to the hide_btn.click event, which is not valid. Instead you can pass the cam (gr.Image).\nAlso you need set visibility in the gradio dynamically so use gr.update() function.</p>\n<p>Below is the code changed required to hide the cam. If you want to have toggle functionality you need to pass on the state in the function.</p>\n<pre><code>def hide_cam():\n    return gr.update(visible=False)\n\nhide_btn.click(fn=hide_cam, inputs=[], outputs=cam)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/79052556/gradio-how-to-hide-a-webcam-interface"
  },
  {
    "question": "cannot import name &#39;TypeAliasType&#39; from &#39;typing_extensions&#39; while importing gradio in google colab",
    "answer": "<p>I faced a similar problem for the last couple of days and tried almost all the solutions available. Finally what worked was simply upgrading <strong>typing_extensions</strong></p>\n<pre><code>pip install typing_extensions&gt;=4.5 --upgrade\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/77707299/cannot-import-name-typealiastype-from-typing-extensions-while-importing-grad"
  },
  {
    "question": "I cannot import name &#39;TypeAliasType&#39; from &#39;typing_extensions&#39;",
    "answer": "<p>If your are on colab just restart your runtime and then run the code line again.\nNote: When ever you install gradio restart your runtime. <br>Install gradio as:</p>\n<p><code>%pip install jiwer gradio typing-extensions</code></p>\n",
    "link": "https://stackoverflow.com/questions/77450322/i-cannot-import-name-typealiastype-from-typing-extensions"
  },
  {
    "question": "When using the ChatInterface, how to remove -or edit- the &quot;Chatbot&quot; leyend on top left?",
    "answer": "<p>You can remove the &quot;Chatbot&quot;-item by adding custom CSS. By inspecting the html-file I found out that this item is a <code>label</code>-element with the class tag <code>svelte-1b6s6s</code>. See below for a working example for gradio version <code>4.26.0</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\n\ncss = &quot;&quot;&quot;\nlabel.svelte-1b6s6s {visibility: hidden}\n&quot;&quot;&quot;\n\nwith gr.Blocks(css=css) as demo:\n   \n   gr.ChatInterface(&quot;&quot;)\n\ndemo.launch()\n</code></pre>\n<p>Disclaimer: I have not double checked if other labels are using the same tag as well which would result in unintentionally hiding other items.</p>\n",
    "link": "https://stackoverflow.com/questions/76898750/when-using-the-chatinterface-how-to-remove-or-edit-the-chatbot-leyend-on-to"
  },
  {
    "question": "Python, Gradio, promise chains, .then(), understanding passed and operated data",
    "answer": "<p>Yeah it's definitely a little bit confusing, but yes .then is very similar to promise chaining that you can find in javascript and it is part of Gradio, not python. It just completes the inputs and outputs basically as side effects (outputs change values), then passes to the next function all the inputs and outputs for that specific block. This is different from javascript because you can't really affect other than outputting a new value from functions so it's a gray area for sure.</p>\n<p>The other part of it is these is event listeners which are a little different than promises (see <a href=\"https://stackoverflow.com/a/46870597/6637798\">https://stackoverflow.com/a/46870597/6637798</a>) so it's not exactly going to need to follow the promise chaining you know form js.</p>\n",
    "link": "https://stackoverflow.com/questions/76285990/python-gradio-promise-chains-then-understanding-passed-and-operated-data"
  },
  {
    "question": "Gradio How to add user avatar in chat interface",
    "answer": "<p>Two things to add: the order of the images you provide via avatar_images is fixed. You may also need to define the path where the images are located via the gr.set_static_paths so that gradio can access them, ie:</p>\n<pre><code>gr.set_static_paths(paths=[&quot;assets/&quot;])\n</code></pre>\n<p>And then you provide the images as this:</p>\n<pre><code>(...)\nchatbot = gr.Chatbot(\n    avatar_images='assets/avatar_human.PNG','assets/avatar_AI.PNG'),\n    (...)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/78948247/gradio-how-to-add-user-avatar-in-chat-interface"
  },
  {
    "question": "how to change favicon in Gradio python",
    "answer": "<p>You have to just provide path to your favicon</p>\n<pre><code>import time\nimport gradio as gr\n\ndef slow_echo(message, history):\n  for i in range(len(message)):\n      time.sleep(0.3)\n      yield &quot;You typed: &quot; + message[: i+1]\n\ngr.ChatInterface(slow_echo).launch(favicon_path='fav.jpg')\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/78947142/how-to-change-favicon-in-gradio-python"
  },
  {
    "question": "Gradio app works fine using simple Dockerfile, but fails when using docker-compose",
    "answer": "<p>docker-compose.yml</p>\n<pre><code>services:\n  my_gradio:\n    build: .\n    ports:\n      - &quot;7860:7860&quot;\n    networks:\n      - net\n    environment:\n      - GRADIO_SERVER_NAME=0.0.0.0\n      - GRADIO_SERVER_PORT=7860\n\nnetworks:\n  net:\n\n</code></pre>\n<p>i tested in my machine and as per the comment removing the double quote from <code>GRADIO_SERVER_NAME</code> value worked fine and the app was running fine with <code>docker compose</code>.</p>\n<p><a href=\"https://i.sstatic.net/2zxefdM6.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/2zxefdM6.png\" alt=\"enter image description here\" /></a></p>\n<p>browser:\n<a href=\"https://i.sstatic.net/yrEjAXD0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/yrEjAXD0.png\" alt=\"enter image description here\" /></a></p>\n",
    "link": "https://stackoverflow.com/questions/78943733/gradio-app-works-fine-using-simple-dockerfile-but-fails-when-using-docker-compo"
  },
  {
    "question": "How to resolve Import Error when using quantization in bitsandbytes",
    "answer": "<p>You can try restarting or reconnecting your gpu and reinstalling library again using:</p>\n<pre><code>pip install -q -U bitsandbytes\npip install -q -U git+https://github.com/huggingface/transformers.git\npip install -q -U git+https://github.com/huggingface/peft.git\npip install -q -U git+https://github.com/huggingface/accelerate.git\n</code></pre>\n<p>For more information you can checkout at: <a href=\"https://huggingface.co/blog/4bit-transformers-bitsandbytes\" rel=\"nofollow noreferrer\">https://huggingface.co/blog/4bit-transformers-bitsandbytes</a></p>\n",
    "link": "https://stackoverflow.com/questions/78521037/how-to-resolve-import-error-when-using-quantization-in-bitsandbytes"
  },
  {
    "question": "Simple Gradio App in Docker Container does not work in Azure Container Registrey f&#252;r Azure Webapp",
    "answer": "<p>Your Dockerfile contains,</p>\n<blockquote>\n<p>CMD [&quot;./app.py&quot;, &quot;--server.port=0000&quot;, &quot;--server.port=7860&quot; ]</p>\n</blockquote>\n<p>In CMD command where <code>--server.port=0000</code> should not be there. It should simply specify <code>--server.port=7860</code>.</p>\n<p>I used below dockerfile and deployed the gradio app to Azure app service through Azure container registry without any issue.</p>\n<p><strong>Dockerfile</strong>:</p>\n<pre><code>FROM python:3.12\nWORKDIR /app\nCOPY requirements.txt ./\nRUN pip install --no-cache-dir -r requirements.txt\nENV GRADIO_SERVER_PORT=7860\nENV GRADIO_SERVER_NAME=0.0.0.0\nEXPOSE 7860\nCOPY . .\nCMD [&quot;python3&quot;, &quot;app.py&quot;]\n</code></pre>\n<p><strong>app. py</strong>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\ndef greet(name):\n    return f&quot;Hello {name}!&quot;\niface = gr.Interface(fn=greet, inputs=&quot;text&quot;, outputs=&quot;text&quot;)\niface.launch(server_name=&quot;0.0.0.0&quot;, server_port=7860)\n</code></pre>\n<p>For deployment purpose, I created virtual Environment by using below commands.</p>\n<pre><code>python -m venv venv \nvenv\\Scripts\\activate\n</code></pre>\n<p>I used below commands to build and run docker image locally.</p>\n<pre><code>docker build -t &lt;ImageName&gt; .\ndocker run -d -p &lt;LocalPort&gt;:&lt;HostPortInDocker&gt;  &lt;ImageName&gt; \n</code></pre>\n<p><strong>Local Output</strong>:</p>\n<p><img src=\"https://i.imgur.com/lrPUnBg.png\" alt=\"enter image description here\" /></p>\n<p>I used the below commands to push the image to the Azure Container registry.</p>\n<pre><code>az acr login --n &lt;AzureContainerRegistryName&gt;.azurecr.io\ndocker tag &lt;imageName&gt; &lt;AzureContainerRegistryName&gt;.azurecr.io/&lt;imageName&gt;:&lt;tag&gt;\ndocker push  &lt;AzureContainerRegistryName&gt;.azurecr.io/&lt;imageName&gt;:&lt;tag&gt;\n</code></pre>\n<p>While creating web app I selected Container as publish option and Clicked <code>Next:Container</code> button and App service Pricing Plan is <code>Premium V3 P0V3</code> as shown below.</p>\n<p><img src=\"https://i.imgur.com/SvI9O4j.png\" alt=\"enter image description here\" /></p>\n<p><img src=\"https://i.imgur.com/BkpB3Rx.png\" alt=\"enter image description here\" /></p>\n<p><strong>Azure App service Output</strong>:</p>\n<p><img src=\"https://i.imgur.com/9Fv0BN1.png\" alt=\"enter image description here\" /></p>\n",
    "link": "https://stackoverflow.com/questions/78884168/simple-gradio-app-in-docker-container-does-not-work-in-azure-container-registrey"
  },
  {
    "question": "How do I gracefully close (terminate) Gradio from within gradio.Blocks()?",
    "answer": "<p>you can do this</p>\n<pre><code>import gradio as gr\n\ndef my_function(input):\n    output = ...\n    return output\n\niface = gr.Interface(fn=my_function, inputs=&quot;text&quot;, outputs=&quot;text&quot;)\ndef on_close():\niface.set_on_close(on_close)\niface.launch()\niface.close()\n</code></pre>\n<p>I believe this should work</p>\n",
    "link": "https://stackoverflow.com/questions/75286784/how-do-i-gracefully-close-terminate-gradio-from-within-gradio-blocks"
  },
  {
    "question": "Response with Chart in Gradio",
    "answer": "<p>basically you just need to pass the filename to the chatbot and it will visualize the plot:</p>\n<pre><code>import gradio as gr\nimport plotly.express as px\nfrom tempfile import NamedTemporaryFile\n\n\ndef random_plot():\n    df = px.data.iris()\n    fig = px.scatter(df, x=&quot;sepal_width&quot;, y=&quot;sepal_length&quot;, color=&quot;species&quot;,\n                    size='petal_length', hover_data=['petal_width'])\n    \n    # save plot into temp file\n    ff = NamedTemporaryFile(suffix=&quot;.jpg&quot;, delete=False)\n    print(ff.name)\n    fig.write_image(ff)\n    messages = [(None,(ff.name,))]\n    return messages\n\n\nwith gr.Blocks(fill_height=True) as demo:\n\n    chatbot = gr.Chatbot(\n        value = random_plot,\n        elem_id=&quot;chatbot&quot;,\n    )\n\n\ndemo.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/78854675/response-with-chart-in-gradio"
  },
  {
    "question": "Returns : ModuleNotFoundError: No module named &#39;gradio&#39; when I try to run my program",
    "answer": "<p>Looks like it isn't installed.\nRun this command in the terminal:</p>\n<pre><code>pip install gradio\n</code></pre>\n<p>If it is installed and code still throws the same error, then place these two lines first:</p>\n<pre><code>import sys\nsys.path.append( path_to_the_gradio_module )\n\nimport openai\nimport gradio\n# ...\n</code></pre>\n<p>But you need to replace <code>path_to_the_gradio_module</code> with the actual path to this module. For example (this path will not work. You should understand from this path what I mean): <code>C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python3.VERSION\\\\Lib\\\\Gradio</code></p>\n",
    "link": "https://stackoverflow.com/questions/75904667/returns-modulenotfounderror-no-module-named-gradio-when-i-try-to-run-my-pro"
  },
  {
    "question": "Sequential bot messages in Gradio ChatInterface",
    "answer": "<p>I would propose to go with custom chat interface. I don't think that current version of prebuild <code>ChatInterface</code> can do the work that you want it to do.</p>\n<pre><code>import gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    clear = gr.Button(&quot;Clear&quot;)\n\n    def user(user_message, history):\n        return &quot;&quot;, history + [[user_message, None]]\n\n    def bot_message(history):\n        bot_message = random.choice([&quot;How are you?&quot;, &quot;I love you&quot;, &quot;I'm very hungry&quot;])\n        history.append((None, bot_message))\n        return history        \n\n    def bot2_message(history):\n        bot_message = random.choice([&quot;Hello2&quot;])\n        history.append((None, bot_message))\n        return history\n\n\n    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n        bot_message, chatbot, chatbot\n    ).then(\n        bot2_message, chatbot, chatbot\n    )\n    clear.click(lambda: None, None, chatbot, queue=False)\n\ndemo.launch()\n\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/78852968/sequential-bot-messages-in-gradio-chatinterface"
  },
  {
    "question": "Gradio - Way to show active hyperlink on chatbot output",
    "answer": "<p>You can use markdown:</p>\n<pre><code>def my_function(text):\nhref = &quot;https://www.google.com/&quot;\nreturn f&quot;[This is a link to Google]({href})&quot;\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76770042/gradio-way-to-show-active-hyperlink-on-chatbot-output"
  },
  {
    "question": "Gradio word predictor: Cannot call click outside of a gradio.Blocks context",
    "answer": "<p>As per the docs regarding the <code>gr.Blocks()</code>, logic should be separated from the UI block.</p>\n<p>So for example , instead of doing:</p>\n<pre><code>if len(pred_words) == 0:\n        empty_preds = gr.Row()\n        empty_preds.add(gr.Textbox(placeholder=&quot;No predictions&quot;, label=&quot;Predictions&quot;))\n        return empty_preds\n</code></pre>\n<p>simply return a string:</p>\n<pre><code>    if len(pred_words) == 0:\n        return &quot;There are no predictions&quot;\n</code></pre>\n<p>and then in the UI block, handle the change by using the get_predictions as a callback.</p>\n",
    "link": "https://stackoverflow.com/questions/78503904/gradio-word-predictor-cannot-call-click-outside-of-a-gradio-blocks-context"
  },
  {
    "question": "Can&#39;t Install PIP Gradio",
    "answer": "<p>You do not appear to be using an activated virtual environment. As can be seen on <a href=\"https://pypi.org/project/gradio/#description\" rel=\"nofollow noreferrer\">PyPi</a>:</p>\n<blockquote>\n<p>It is best to install Gradio in a virtual environment.</p>\n</blockquote>\n<p>The <a href=\"https://www.gradio.app/main/guides/installing-gradio-in-a-virtual-environment\" rel=\"nofollow noreferrer\">docs</a> describes a virtual environment:</p>\n<blockquote>\n<p>A virtual environment in Python is a self-contained directory that holds a Python installation for a particular version of Python, along with a number of additional packages. This environment is isolated from the main Python installation and other virtual environments. Each environment can have its own independent set of installed Python packages, which allows you to maintain different versions of libraries for different projects without conflicts. Using virtual environments ensures that you can work on multiple Python projects on the same machine without any conflicts. This is particularly useful when different projects require different versions of the same library. It also simplifies dependency management and enhances reproducibility, as you can easily share the requirements of your project with others.</p>\n</blockquote>\n<p>It goes further to give <strong>guidelines for installing Gradio on a Windows system in a virtual environment</strong>:</p>\n<ol>\n<li><strong>Create a Virtual Environment</strong>: Open Command Prompt and navigate to your project directory. Then create a virtual environment using the following command:</li>\n</ol>\n<pre><code>python -m venv gradio-env\n</code></pre>\n<p>This command creates a new directory <em>gradio-env</em> in your project folder, containing a fresh Python installation.</p>\n<ol start=\"2\">\n<li><strong>Activate the Virtual Environment</strong>: To activate the virtual environment, run:</li>\n</ol>\n<pre><code>.\\gradio-env\\Scripts\\activate\n</code></pre>\n<p>Your command prompt should now indicate that you are working inside <em>gradio-env</em>. Note: you can choose a different name than <em>gradio-env</em> for your virtual environment in this step.</p>\n<ol start=\"3\">\n<li><strong>Install Gradio</strong>: Now, you can install Gradio using pip:</li>\n</ol>\n<pre><code>pip install gradio\n</code></pre>\n<ol start=\"4\">\n<li><strong>Verification</strong>: To verify the installation, run python and then type:</li>\n</ol>\n<pre><code>import gradio as gr\nprint(gr.__version__)\n</code></pre>\n<p>This will display the installed version of Gradio.</p>\n<p>See <a href=\"https://www.gradio.app/main/guides/installing-gradio-in-a-virtual-environment\" rel=\"nofollow noreferrer\">the docs</a>.</p>\n",
    "link": "https://stackoverflow.com/questions/78831835/cant-install-pip-gradio"
  },
  {
    "question": "Can gradio functions return components",
    "answer": "<p>Figured out a solution from the documentation. The trick is using the <code>@gr.render</code> decorator:</p>\n<pre class=\"lang-py prettyprint-override\"><code># interface\nwith gr.Blocks() as los_generation_iface:\n  gr.Markdown(&quot;## Generate Learning Objectives&quot;)\n\n  with gr.Column():\n    task_id_dropdown = gr.Dropdown(label='Choose Content', choices=os.listdir(path=env.STORAGE_PATH))\n\n  # load content\n  @gr.render(inputs=[task_id_dropdown])\n  def load_content(task_id: str):\n    # error handling\n    if task_id is None:\n      return\n\n    # read tsh\n    dao = FileStorageAccessObject(id=task_id)\n    tsh = dao.read(identifier='tsh')\n\n    # custom component\n    with gr.Blocks() as block:\n      for (key, value) in tsh.items():\n        with gr.Row():\n          with gr.Column():\n            gr.Textbox(value=key)\n          with gr.Column():\n            gr.Textbox(value=value)\n          with gr.Column():\n            gr.Checkbox(label='Accept', value=False)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/78727272/can-gradio-functions-return-components"
  },
  {
    "question": "Passing data to gradio Dataframe from JavaScript",
    "answer": "<p>Creators of gradio replied:</p>\n<blockquote>\n<p>This isn't really possible using this approach but gradio custom component are designed to address this exact use case. <a href=\"https://www.gradio.app/guides/custom-components-in-five-minutes\" rel=\"nofollow noreferrer\">https://www.gradio.app/guides/custom-components-in-five-minutes</a></p>\n</blockquote>\n<p>So, I'll try to do it there.</p>\n",
    "link": "https://stackoverflow.com/questions/78697262/passing-data-to-gradio-dataframe-from-javascript"
  },
  {
    "question": "In a gradio tab GUI, a button calls the other tab",
    "answer": "<p>Yes, tabbed gradio was buggy. It was fixed in version 4.36.1\nSee the <a href=\"https://www.gradio.app/changelog#4-36-1\" rel=\"nofollow noreferrer\">changelog</a>:</p>\n<blockquote>\n<p>Fixes TabbedInterface bug where only first interface events get triggered.</p>\n</blockquote>\n<p>This explains the differences you see between both versions (4.32.2 &lt; 4.36.1 &lt; 4.37.2)</p>\n",
    "link": "https://stackoverflow.com/questions/78695836/in-a-gradio-tab-gui-a-button-calls-the-other-tab"
  },
  {
    "question": "How to save the chat historial of gradio.Chatbot",
    "answer": "<p>Your case happened because <code>with open('data.yaml', 'w') as file:</code> overwrite the file. Try to use <code>with open('data.yaml', 'a')</code>, so it appends the file.</p>\n",
    "link": "https://stackoverflow.com/questions/76642994/how-to-save-the-chat-historial-of-gradio-chatbot"
  },
  {
    "question": "How to Load an Image onto a Canvas in Gradio with Custom HTML and JavaScript?",
    "answer": "<p>You can see it in many questions or tutorials</p>\n<p>You have to get canvas, next get it context <code>.getContext('2d')</code> and next put image with <code>.drawImage(img, x, y, width, height)</code></p>\n<p>Something like this</p>\n<pre><code>var image  = document.getElementById(&quot;image&quot;);\nvar canvas = document.getElementById(&quot;canvas&quot;);\nvar ctx = canvas.getContext('2d');\nctx.drawImage(image, 0, 0);\n</code></pre>\n<p>But I found out that <code>gr.HTML()</code> can't run <code>&lt;script&gt;</code> and this makes problem how to run above code.</p>\n<p>But you may add script to <code>gr.Block(js=script)</code> with function which later you can use in <code>onclick=&quot;..&quot;</code> assigned to button or in <code>onload=&quot;...&quot;</code> assigned to image.</p>\n<hr />\n<p>Full code:</p>\n<pre><code>import gradio as gr\nimport numpy as np\nimport base64\nfrom PIL import Image\nfrom io import BytesIO\n\ndef image_to_base64(img):\n    buffered = BytesIO()\n    img.save(buffered, format=&quot;PNG&quot;)\n    img_str = base64.b64encode(buffered.getvalue()).decode(&quot;utf-8&quot;)\n    return img_str\n\ndef image_uploaded(img):\n    img_pil = Image.fromarray(img)\n    img_str = image_to_base64(img_pil)\n\n    img_str = f'data:image/png;base64,{img_str}'\n    #img_str = f'https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png'\n    \n    # HTML content with a canvas element\n    html_content = f&quot;&quot;&quot;\n&lt;h1&gt;Uploaded: img&lt;/h1&gt;\n\n&lt;img id=&quot;image&quot; src=&quot;{img_str}&quot; alt=&quot;&quot; onload=&quot;draw_image();&quot;&gt;\n\n&lt;h1&gt;Uploaded: canvas&lt;/h1&gt;\n\n&lt;canvas id=&quot;canvas&quot; width=&quot;600&quot;&gt;&lt;/canvas&gt;\n\n&lt;!-- &lt;button onclick=&quot;draw_image();&quot; style=&quot;background-color:#eee;padding:25px&quot;&gt;Draw Image&lt;/button&gt;  --&gt;\n&quot;&quot;&quot;\n\n    return img, html_content\n\nscript = &quot;&quot;&quot;\n/* this function is executed automatically at start (not when you load canvas) */\n/* so draw_image() has to be inside (not in place of `async ()`) */\nasync () =&gt; {\n    globalThis.draw_image = () =&gt; {\n        var image  = document.getElementById(&quot;image&quot;);\n        var canvas = document.getElementById(&quot;canvas&quot;);\n        var ctx = canvas.getContext('2d');\n        ctx.drawImage(image, 0, 0);\n    }\n}\n&quot;&quot;&quot;\n\nwith gr.Blocks(js=script) as demo:\n    uploaded_image = gr.Image(type=&quot;numpy&quot;, show_label=False, interactive=True, show_download_button=False)\n    original_image = gr.Image(type=&quot;numpy&quot;, interactive=False, show_label=False, show_download_button=False)\n\n    bounding_box_editor = gr.HTML()\n    \n    uploaded_image.upload(image_uploaded, inputs=uploaded_image, outputs=[original_image, bounding_box_editor])\n    \ndemo.launch(share=False)\n</code></pre>\n<hr />\n<p>Source of information:</p>\n<ul>\n<li><p><a href=\"https://discuss.huggingface.co/t/gradio-html-component-with-javascript-code-dont-work/37316\" rel=\"nofollow noreferrer\">Gradio HTML component with javascript code don't work - üîí Gradio - Hugging Face Forums</a></p>\n</li>\n<li><p><a href=\"https://www.gradio.app/guides/custom-CSS-and-JS#adding-custom-java-script-to-your-demo\" rel=\"nofollow noreferrer\">Custom CSS And JS</a></p>\n</li>\n<li><p><a href=\"https://github.com/gradio-app/gradio/issues/3446\" rel=\"nofollow noreferrer\">gradio.HTML CAN NOT load my javascript ¬∑ Issue #3446 ¬∑ gradio-app/gradio</a></p>\n</li>\n<li><p><a href=\"https://www.w3schools.com/jsref/canvas_drawimage.asp\" rel=\"nofollow noreferrer\">HTML canvas drawImage() Method</a></p>\n</li>\n</ul>\n<hr />\n<p>Code which add second image (image <a href=\"https://en.wikipedia.org/wiki/Lenna\" rel=\"nofollow noreferrer\">Lenna</a> from Wikipedia) and you can use buttons to select which image put on canvas.</p>\n<pre><code>import gradio as gr\nimport numpy as np\nimport base64\nfrom PIL import Image\nfrom io import BytesIO\n\ndef image_to_base64(img):\n    buffered = BytesIO()\n    img.save(buffered, format=&quot;PNG&quot;)\n    img_str = base64.b64encode(buffered.getvalue()).decode(&quot;utf-8&quot;)\n    return img_str\n\ndef image_uploaded(img):\n    img_pil = Image.fromarray(img)\n    img_str = image_to_base64(img_pil)\n\n    img_str_1 = f'data:image/png;base64,{img_str}'\n    img_str_2 = f'https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png'\n    \n    # HTML content with a canvas element\n    html_content = f&quot;&quot;&quot;\n&lt;h1&gt;Uploaded: img&lt;/h1&gt;\n\n&lt;img id=&quot;image1&quot; src=&quot;{img_str_1}&quot; alt=&quot;&quot; width=&quot;200&quot; height=&quot;200&quot;&gt; &lt;img id=&quot;image2&quot; src=&quot;{img_str_2}&quot; alt=&quot;&quot; width=&quot;200&quot; height=&quot;200&quot;&gt;\n\n&lt;h1&gt;Uploaded: canvas&lt;/h1&gt;\n\n&lt;canvas id=&quot;canvas&quot; width=&quot;200&quot; height=&quot;200&quot;&gt;&lt;/canvas&gt;\n\n&lt;button onclick=&quot;draw_image('image1');&quot; style=&quot;background-color:#eee;padding:25px&quot;&gt;Draw Image 1&lt;/button&gt;\n&lt;button onclick=&quot;draw_image('image2');&quot; style=&quot;background-color:#eee;padding:25px&quot;&gt;Draw Image 2&lt;/button&gt;\n&quot;&quot;&quot;\n\n    return img, html_content\n\nscript = &quot;&quot;&quot;\n/* this function is executed automatically at start (not when you load canvas) */\n/* so draw_image() has to be inside (not in place of `async ()`) */\nasync () =&gt; {\n    globalThis.draw_image = (image_id) =&gt; {\n        var image  = document.getElementById(image_id);\n        var canvas = document.getElementById(&quot;canvas&quot;);\n        var ctx = canvas.getContext('2d');\n        ctx.drawImage(image, 0, 0, 200, 200);\n    }\n}\n&quot;&quot;&quot;\n\nwith gr.Blocks(js=script) as demo:\n    uploaded_image = gr.Image(type=&quot;numpy&quot;, show_label=False, interactive=True, show_download_button=False)\n    original_image = gr.Image(type=&quot;numpy&quot;, interactive=False, show_label=False, show_download_button=False)\n\n    bounding_box_editor = gr.HTML()\n    \n    uploaded_image.upload(image_uploaded, inputs=uploaded_image, outputs=[original_image, bounding_box_editor])\n    \ndemo.launch(share=False)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/78682661/how-to-load-an-image-onto-a-canvas-in-gradio-with-custom-html-and-javascript"
  },
  {
    "question": "Possible Way to have OpenAI code run on Flet?",
    "answer": "<p>Firstly, the <code>&lt;</code> and <code>&gt;</code> should not be included in your app name. Also, it is better to not use any white spaces in your name when dealing with the command line interface. You should do something like:</p>\n<pre><code>flet create chatbot\n</code></pre>\n<p>Note that it is generally not safe to post your API key in a public forum, as other malicious individuals can use it and eat up your credit.</p>\n<p>You can create a similar chatbot in flet.</p>\n<pre class=\"lang-py prettyprint-override\"><code># Inside chatbot.py\nfrom openai import OpenAI\nimport flet as ft\n\nclient = OpenAI(\n    api_key=&quot;YOUR_API_KEY&quot;,\n)\nmessages = [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a medical professional tasked in the at-home treatment of someone suffering from one of many chronic diseases&quot;}]\n\ndef CustomChatGPT(user_input):\n    messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_input})\n    response = client.chat.completions.create(\n        model=&quot;gpt-3.5-turbo&quot;,\n        messages=messages\n    )\n    reply = response.choices[0].message.content\n    messages.append({&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: reply})\n    return reply\n\ndef main(page: ft.Page):\n    page.title = &quot;Oliver's Chronic Disease Chatbot&quot;\n    \n    def send_message(e):\n        user_input = input_box.value\n        if user_input:\n            output_box.value += f&quot;You: {user_input}\\n&quot;\n            response = CustomChatGPT(user_input)\n            output_box.value += f&quot;Bot: {response}\\n&quot;\n            input_box.value = &quot;&quot;\n            page.update()\n\n    # UI\n    input_box = ft.TextField(label=&quot;Your message&quot;, width=500)\n    send_button = ft.ElevatedButton(text=&quot;Send&quot;, on_click=send_message)\n    output_box = ft.TextField(value=&quot;&quot;, multiline=True, read_only=True, width=500, height=300)\n\n    page.add(ft.Column([output_box, input_box, send_button]))\n\nft.app(target=main)\n</code></pre>\n<p>Remember to add your own API_KEY, you can test whether it works on your desktop by running it:</p>\n<pre><code>flet create chatbot.py\nflet run chatbot\n</code></pre>\n<p>I am not familiar with flet but I am assuming it is similar to other mobile application frameworks. To run it on your phone, it is slightly more complicated, especially if you are using an iOS device. Assuming you are using Android, you need to bundle this app into an apk, and send the file to your phone.</p>\n<p>You can look into the <a href=\"https://flet.dev/docs/publish/android/\" rel=\"nofollow noreferrer\">documentation</a>.</p>\n<p>Finally, note that putting API keys and other secrets on the client side is generally considered bad practice for security and practical reasons (what if you change your API key?).</p>\n<p>A better alternative would be to use serverless functions for small applications like yours, such as Firebase's <a href=\"https://firebase.google.com/docs/functions\" rel=\"nofollow noreferrer\">cloud functions</a>.</p>\n",
    "link": "https://stackoverflow.com/questions/78680213/possible-way-to-have-openai-code-run-on-flet"
  },
  {
    "question": "Gradio error: TypeError: gradio.data_classes.FileData() argument after ** must be a mapping, not list",
    "answer": "<p>All problem is <code>file_count=1</code></p>\n<p>Documentation for <a href=\"https://www.gradio.app/docs/gradio/file\" rel=\"nofollow noreferrer\">File</a> shows allowed values:</p>\n<ul>\n<li><code>file_count=&quot;single&quot;</code>   (it is default value)</li>\n<li><code>file_count=&quot;multiple&quot;</code></li>\n<li><code>file_count=&quot;directory&quot;</code></li>\n</ul>\n<p>So you need</p>\n<pre class=\"lang-py prettyprint-override\"><code>file_input = gr.File(label=&quot;Excel or CSV file&quot;, elem_classes=&quot;custom-file-input&quot;, file_count=&quot;single&quot;)\n</code></pre>\n<p>or you can even skip <code>file_count=&quot;single&quot;</code> because it is default value</p>\n<pre class=\"lang-py prettyprint-override\"><code>file_input = gr.File(label=&quot;Excel or CSV file&quot;, elem_classes=&quot;custom-file-input&quot;)\n</code></pre>\n<p>That's all.</p>\n<hr />\n<p>BTW:</p>\n<p>Later you need some small changes.</p>\n<p>In function you needs <code>outputs</code> to show progressbar:</p>\n<pre class=\"lang-py prettyprint-override\"><code>@analyze_button.click(inputs=file_input, outputs=progress_output)\n</code></pre>\n<p>If you want to load <code>csv</code> then you have to run <code>read_csv</code></p>\n<pre class=\"lang-py prettyprint-override\"><code>if file.name.endswith('csv'):\n    df = pd.read_csv(file.name)\nelse:\n    df = pd.read_excel(file.name)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/78669198/gradio-error-typeerror-gradio-data-classes-filedata-argument-after-must-b"
  },
  {
    "question": "How can I convert Gradio app to flask api?",
    "answer": "<p>If you need image (as <code>PIL</code>) only on server then you can use directly</p>\n<pre><code>from PIL import Image\n\ncloth_image = Image.open( request.files[&quot;cloth_image&quot;] )\n</code></pre>\n<p>Because <code>files[&quot;cloth_image&quot;]</code> has method <code>.read()</code> so it can be treated as file-like object, and <code>Image.open()</code> can use file-like object instead of filename.</p>\n<p>And you can convert between <code>pillow</code> and <code>numpy</code>(and <code>opencv</code>)</p>\n<pre><code># from pillow to numpy/opencv\narr = numpy.array(cloth_image)\n\n# from numpy/opencv to pillow\ncloth_image = Image.fromarray(arr)\n</code></pre>\n<p>(<code>opencv</code> may need to convert colors between <code>RGB</code> and <code>BGR</code>)</p>\n<hr />\n<p>Minimal working code:</p>\n<pre><code>from flask import Flask, request\nfrom PIL import Image\n\napp = Flask(__name__)\n\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    if request.method == 'POST':\n        if &quot;cloth_image&quot; in request.files:\n            img = request.files[&quot;cloth_image&quot;]  # it has method .read() so it can be treated as file-like object\n            cloth_image = Image.open(img)  # it can use file-like object instead of filename\n            # ... process image ...\n\n    return &quot;&quot;&quot;\n    &lt;form method=&quot;POST&quot; enctype=&quot;multipart/form-data&quot;&gt;\n    &lt;input type=&quot;file&quot; name=&quot;cloth_image&quot;&gt;\n    &lt;button type=&quot;submit&quot;&gt;Send&lt;/button&gt;\n    &lt;/form&gt;&quot;&quot;&quot;\n\nif __name__ == '__main__':\n    app.run()\n</code></pre>\n<p>But if you need to send it back then you may need to use <code>io.BytesIO</code> to save image in file-like object in memory, convert it to <code>base64</code>, and display it as</p>\n<pre><code>html = '&lt;img src=&quot;data:image/png;base64,{}&quot;&gt;'.format(data)\n</code></pre>\n<p>More complex code which gets image, draw rectangle and send it back to browser.</p>\n<pre><code>from flask import Flask, request\nfrom PIL import Image, ImageDraw\nimport io\nimport base64\n\napp = Flask(__name__)\n\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    img = 'empty'\n    \n    if request.method == 'POST':\n        if &quot;image&quot; in request.files:\n            print(request.files)\n\n            # get image\n            img = request.files[&quot;image&quot;]   # it has method .read()\n\n            # read to pillow\n            image = Image.open(img)\n\n            # draw something\n            draw = ImageDraw.Draw(image)                                      # https://pillow.readthedocs.io/en/stable/reference/ImageDraw.html\n            draw.rectangle([(20,20), (280,280)], outline=(255,0,0), width=3)  # https://pillow.readthedocs.io/en/stable/reference/ImageDraw.html#PIL.ImageDraw.ImageDraw.rectangle\n            draw.text((15,5), &quot;Hello World!&quot;)                                 # https://pillow.readthedocs.io/en/stable/reference/ImageDraw.html#PIL.ImageDraw.ImageDraw.text\n\n            # convert to file-like data\n            obj = io.BytesIO()             # file in memory to save image without using disk  #\n            image.save(obj, format='png')  # save in file (BytesIO)                           # https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.save\n            obj.seek(0)\n\n            # convert to bases64\n            data = obj.read()              # get data from file (BytesIO)\n            data = base64.b64encode(data)  # convert to base64 as bytes\n            data = data.decode()           # convert bytes to string\n\n            # convert to &lt;img&gt; with embed image\n            img = '&lt;img src=&quot;data:image/png;base64,{}&quot;&gt;'.format(data)\n\n    return '&lt;form method=&quot;POST&quot; enctype=&quot;multipart/form-data&quot;&gt;&lt;input type=&quot;file&quot; name=&quot;image&quot;&gt;&lt;button type=&quot;submit&quot;&gt;Send&lt;/button&gt;&lt;/form&gt;&lt;br&gt;' + img\n\nif __name__ == '__main__':\n    app.run()\n</code></pre>\n<hr />\n<p>And if you need it without reloading page then you may have to use JavaScript. But I skip this problem.</p>\n",
    "link": "https://stackoverflow.com/questions/78643476/how-can-i-convert-gradio-app-to-flask-api"
  },
  {
    "question": "How to resize an image in Gradio?",
    "answer": "<p>Documentation for <a href=\"https://www.gradio.app/docs/gradio/image\" rel=\"nofollow noreferrer\">Image</a> shows that you can use</p>\n<pre><code>Image(..., width=..., height=...)\n</code></pre>\n<p>I test it and it works but it can't be smaller than <code>width=160</code>.<br />\nAnd it needs to change also <code>min_width=</code> to smaller value because it has default value <code>160</code></p>\n<hr />\n<p>If you don't need label and download button then you can uses</p>\n<pre><code>Image(..., show_label=False, show_download_button=False)\n</code></pre>\n<hr />\n<p>If you want to put own <code>&lt;img src=&quot;...&quot;&gt;</code> then it can make problem because <code>DevTools</code> in Firefox/Chrome shows that it uses path like this</p>\n<pre class=\"lang-none prettyprint-override\"><code>http://0.0.0.0:7860/file=/tmp/user/1000/gradio/f1ca8fcde634bae0360273c73b61af0bac43f7a8/logo.png\n</code></pre>\n<p>Maybe there is random value or maybe it is hash value calculated for this file.</p>\n<p>I checked it created file on disk (on Linux)</p>\n<pre class=\"lang-none prettyprint-override\"><code>/tmp/user/1000/gradio/f1ca8fcde634bae0360273c73b61af0bac43f7a8/logo.png\n</code></pre>\n<hr />\n<p>I found that you can use local file if you add it to <code>allowed_path</code> in <code>app.launch()</code></p>\n<p><code>src=&quot;/file=logo.png&quot;</code><br />\n<code>app.launch(..., allowed_paths=[&quot;logo.png&quot;])</code></p>\n<pre><code>image_path = &quot;logo.png&quot;\ngr.HTML(f&quot;&quot;&quot;&lt;img src=&quot;/file={image_path}&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;&quot;&quot;&quot;)\n    \napp.launch(server_name=&quot;0.0.0.0&quot;, server_port=7860, debug=True, \n           allowed_paths=[image_path])\n</code></pre>\n<p>You may also use folder (absolute or relative)</p>\n<p><code>src=&quot;/file=/some/folder/logo.png&quot;</code><br />\n<code>app.launch(..., allowed_paths=[&quot;/some/folder/&quot;])</code></p>\n<pre><code>folder = &quot;/other/folder&quot;\n\nimage_path_1 = f&quot;{folder}/logo.png&quot;\ngr.HTML(f&quot;&quot;&quot;&lt;img src=&quot;/file={image_path_1}&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;&quot;&quot;&quot;)\n\nimage_path_2 = f&quot;{folder}/other.png&quot;\ngr.HTML(f&quot;&quot;&quot;&lt;img src=&quot;/file={image_path_2}&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;&quot;&quot;&quot;)\n    \napp.launch(server_name=&quot;0.0.0.0&quot;, server_port=7860, debug=True, \n           allowed_paths=[folder])\n</code></pre>\n<p>It can be relative folder</p>\n<p><code>src=&quot;/file=subfolder/images/logo.png&quot;</code><br />\n<code>app.launch(..., allowed_paths=[&quot;subfolder/images/&quot;])</code></p>\n<p>or you may create absolute path</p>\n<pre><code>absolute_folder = os.path.join(os.path.dirname(os.path.abspath(__file__)), &quot;subfolder&quot;, &quot;images&quot;)\n</code></pre>\n<p>and this path you have to use in <code>src=&quot;/file=...&quot;</code> and add to <code>allowed_paths</code>.</p>\n<hr />\n<p>There is also <a href=\"https://www.gradio.app/docs/gradio/set_static_paths\" rel=\"nofollow noreferrer\">set_static_paths</a> to add folder with static elements - like layout graphics, logo.</p>\n<pre><code>gr.set_static_paths(paths=[&quot;static/images/&quot;])\n\nimage_path = &quot;static/images/logo.png&quot;\n\ngr.HTML(f&quot;&quot;&quot;&lt;img src=&quot;/file={image_path}&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;&quot;&quot;&quot;)\n</code></pre>\n<p>and this doesn't need to add to <code>allowed_paths</code></p>\n",
    "link": "https://stackoverflow.com/questions/78633756/how-to-resize-an-image-in-gradio"
  },
  {
    "question": "using third party script with NextJS",
    "answer": "<p>Personally I've had bad luck trying to use Web Components in Next.js, but how about using an <code>iframe</code>?</p>\n<pre><code>&lt;iframe src = &quot;https://multimodalart-hallo.hf.space&quot; /&gt;\n</code></pre>\n<p>I tried it out and it works, you'd have to style it up a bit to show it in the appropriate dimensions. Other than that, I don't think there's any downside to using this instead of the Web Component.</p>\n",
    "link": "https://stackoverflow.com/questions/78635046/using-third-party-script-with-nextjs"
  },
  {
    "question": "How to use additional_inputs and examples at the same time?",
    "answer": "<p>Normally you have only one input - for message - so every example needs only one value.</p>\n<p>When you use <code>additional_inputs</code> then you have more inputs<br />\nand every example must have more value - so every example has to be a list (it can't be a tuple).</p>\n<pre><code>examples=[\n  ### [value for textbox, value for input1]  # it can't be tuple\n  [&quot;Hello&quot;, &quot;&quot;], \n  [&quot;Am I cool?&quot;, &quot;&quot;],\n  [&quot;Are tomatoes vegetables?&quot;, &quot;&quot;]\n],\n</code></pre>\n<p>Documentation: <a href=\"https://www.gradio.app/guides/the-interface-class#example-inputs\" rel=\"nofollow noreferrer\">Example Inputs</a></p>\n<hr />\n<p>Full working example with 2 additional inputs - so every example must have 3 values.</p>\n<pre><code>import gradio as gr\n\nprint('gradio:', gr.__version__)\n\ndef yes_man(message, history, input_1, input_2):\n    print('message:', message)\n    print('history:', history)\n    print('input_1:', input_1)\n    print('input_2:', input_2)\n    \n    return f&quot;{message} (I've been {input_1} for {input_2} days)&quot; \n  \nwith gr.Blocks() as demo:     \n      gr.ChatInterface(\n          yes_man, \n          examples=[\n            ### [Example Inputs](https://www.gradio.app/guides/the-interface-class#example-inputs)\n            ### [value for textbox, value for input_1, value for input_2]  # it can't be tuple\n            [&quot;Hello&quot;,                    &quot;nice&quot;, &quot;123&quot;],\n            [&quot;Am I cool?&quot;,               &quot;fun&quot;,  &quot;456&quot;], \n            [&quot;Are tomatoes vegetables?&quot;, &quot;sad&quot;,  &quot;789&quot;],\n            #[&quot;Say something&quot;,           &quot;&quot;,     &quot;&quot;],  # empty values \n          ],\n          additional_inputs=[\n            #gr.Dropdown([&quot;&quot;, &quot;nice&quot;, &quot;fun&quot;, &quot;sad&quot;, &quot;angry&quot;], label=&quot;Mood&quot;), #, allow_custom_value=True),\n            gr.Textbox(&quot;&quot;, label=&quot;Mood&quot;),\n            gr.Textbox(&quot;&quot;, label=&quot;Days&quot;)\n          ],\n      )\n        \ndemo.launch()\n</code></pre>\n<p><a href=\"https://i.sstatic.net/rUgoQfRk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/rUgoQfRk.png\" alt=\"enter image description here\" /></a></p>\n<hr />\n<p>If you set <code>None</code> for some input in all examples then it will not display this column in example\nand example will not change current value in for this input.</p>\n<p>Documentation: <a href=\"https://www.gradio.app/guides/more-on-examples#providing-partial-examples\" rel=\"nofollow noreferrer\">Providing Partial Examples</a></p>\n<pre><code>  examples=[\n    ### [value for textbox, value for input_1, value for input_2]  # it can't be tuple\n    ### [Providing Partial Examples](https://www.gradio.app/guides/more-on-examples#providing-partial-examples)\n    # if column has only `None` then it doesn't display this input  # this will skip `Mood`\n    [&quot;Hello&quot;,                    None, &quot;123&quot;],       \n    [&quot;Am I cool?&quot;,               None, &quot;456&quot;],\n    [&quot;Are tomatoes vegetables?&quot;, None, &quot;789&quot;],\n    [&quot;Say something&quot;,            None, &quot;&quot;],\n  ],\n</code></pre>\n<p><a href=\"https://i.sstatic.net/nhIs5mPN.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/nhIs5mPN.png\" alt=\"enter image description here\" /></a></p>\n",
    "link": "https://stackoverflow.com/questions/78584977/how-to-use-additional-inputs-and-examples-at-the-same-time"
  },
  {
    "question": "a chat with gradio (how to modify its screen appearance)",
    "answer": "<p>I finally achieved what I was looking for modifying the code as</p>\n<pre><code>import requests\nimport gradio as gr\nimport json\n\ndef chat_response(message, history, response_limit):\n    return f&quot;You wrote: {message} and asked {response_limit}&quot;\n\ncss = &quot;&quot;&quot;\n#chatbot {\n    flex-grow: 1 !important;\n    overflow: auto !important;\n}\n#col { height: calc(100vh - 112px - 16px) !important; }\n&quot;&quot;&quot;\n\nwith gr.Blocks(css=css) as demo:\n    gr.Markdown(&quot;# Data Query!&quot;)\n    with gr.Row():\n        with gr.Column(scale=3):\n            response_limit = gr.Number(label=&quot;Response Limit&quot;, value=10, interactive=True)\n        with gr.Column(scale=7,elem_id=&quot;col&quot;):\n            chat = gr.ChatInterface(\n                fn=chat_response,\n                chatbot=gr.Chatbot(elem_id=&quot;chatbot&quot;,\n                                   render=False),\n                additional_inputs=[response_limit]\n            )\n\ndemo.queue()\ndemo.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/78536986/a-chat-with-gradio-how-to-modify-its-screen-appearance"
  },
  {
    "question": "How use Gradio&#39;s gr.Button.click() so that it passes a local variable that is not a Gradio block to the called function?",
    "answer": "<p>One can use a lambda function:</p>\n<pre><code>btn.click(lambda txt_value: dummy(a, txt_value), inputs=[txt], outputs=[answer])\n</code></pre>\n<p>Entire example:</p>\n<pre><code>import gradio as gr\n\ndef dummy(a, b):\n    return '{0} {1}'.format(a, b)\n\nwith gr.Blocks() as demo:\n    a = 'Hello '\n    txt = gr.Textbox(value=&quot;test&quot;, label=&quot;Query&quot;, lines=1)\n    answer = gr.Textbox(value=&quot;&quot;, label=&quot;Answer&quot;)\n    btn = gr.Button(value=&quot;Submit&quot;)\n    btn.click(lambda txt_value: dummy(a, txt_value), inputs=[txt], outputs=[answer])\n    gr.ClearButton([answer])\n\ndemo.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/78536915/how-use-gradios-gr-button-click-so-that-it-passes-a-local-variable-that-is-no"
  },
  {
    "question": "Gradio pop up display on success",
    "answer": "<p>I wanted to do something like what you've mentioned\nI just used</p>\n<pre><code>raise gr.Error(&quot;something here&quot;)\n</code></pre>\n<p>To inform the user by something</p>\n",
    "link": "https://stackoverflow.com/questions/77192757/gradio-pop-up-display-on-success"
  },
  {
    "question": "How can I clear the input in a gradio app automatically?",
    "answer": "<p>Use clear button: <a href=\"https://www.gradio.app/docs/clearbutton\" rel=\"nofollow noreferrer\">https://www.gradio.app/docs/clearbutton</a> .\nGradio provides clear button API for the same use case.</p>\n<p>usage:</p>\n<pre><code>gr.ClearButton(components=list_of_components_you_want_to_clear)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/75815764/how-can-i-clear-the-input-in-a-gradio-app-automatically"
  },
  {
    "question": "I want gradio to show output from files in real-time",
    "answer": "<p>maybe there's something to do with the &quot;every&quot; parameter documented <a href=\"https://www.gradio.app/docs/file\" rel=\"nofollow noreferrer\">here</a>.</p>\n<p><a href=\"https://i.sstatic.net/aWxzG.png\" rel=\"nofollow noreferrer\">docs_of_every_parameter</a></p>\n",
    "link": "https://stackoverflow.com/questions/73923538/i-want-gradio-to-show-output-from-files-in-real-time"
  },
  {
    "question": "I am getting output error after Gradio deployment",
    "answer": "<p>Input and output were deprecated. Use components instead.</p>\n",
    "link": "https://stackoverflow.com/questions/78058612/i-am-getting-output-error-after-gradio-deployment"
  },
  {
    "question": "ImportError: Using `load_in_8bit=True` requires Accelerate: bitsandbytespip: but I have them in the pip freeze",
    "answer": "<p>It seems like there is an issue with transformers version.</p>\n<p>Installing the version 4.37 fixed the issue for me.</p>\n<p><code>pip install transformers==4.37</code></p>\n",
    "link": "https://stackoverflow.com/questions/77411624/importerror-using-load-in-8bit-true-requires-accelerate-bitsandbytespip-but"
  },
  {
    "question": "How to get the upload file location in Gradio?",
    "answer": "<p>Not sure if you're still looking for an answer, but for anyone else who is dealing with file uploads when using <strong>Gradio</strong> I have found the following function (and variations of it) that makes use of the <code>shutil</code> library infinitely useful!</p>\n<pre class=\"lang-py prettyprint-override\"><code>def process_file(fileobj):\n    path = &quot;/home/ubuntu/temps/&quot; + os.path.basename(fileobj)\n    shutil.copyfile(fileobj.name, path)\n    # now you can process the file at path as needed, e.g:\n    # do_something_to_file(path)\n</code></pre>\n<p>Without doing this, I found I had a lot of issues treating the file initially uploaded to Gradio as a <code>tempfile._TemporaryFileWrapper</code> object. I found I was encountering a lot of permission issues and it was hard to do everything I wanted with the object and the <code>tempfile</code> library.</p>\n<p>This new method with <code>shutil</code> gives you complete control over a permanent file object, and if you need to delete it afterwards just add in the code to do so when you're done.</p>\n<p>In the context of using this with Gradio, it would work in a simple example as follows:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\nimport os\nimport shutil\n\ndef process_file(fileobj):\n    path = &quot;/home/ubuntu/temps/&quot; + os.path.basename(fileobj)  #NB*\n    shutil.copyfile(fileobj.name, path)\n    return do_something_to_file(path)\n\ndemo = gr.Interface(\n    fn=process_file,\n    inputs=[\n        &quot;file&quot;,\n    ],\n    outputs=&quot;text&quot;\n)\ndemo.launch(server_name='0.0.0.0')\n</code></pre>\n<p><em>NB:</em> I am doing this on an Ubuntu instance, obviously please modify path name accordingly for your operating system and needs. If you have issues with this method check that you and your python script have permission to write to whichever directory you specify in your path.</p>\n",
    "link": "https://stackoverflow.com/questions/76083621/how-to-get-the-upload-file-location-in-gradio"
  },
  {
    "question": "cannot upload app.py to huggingface space",
    "answer": "<p>UPDATE:\nFor those who are facing this problem like me. I find the solution. If you want to deploy your ML model to the huggingface's space, you need to upload requirement.txt. Yes, requirement.txt is the problem. We don't need to specify the version for each library. For example, gradio==4.22.0, you can write &quot;gradio&quot; instead of a specific version.</p>\n<p>Hope this help</p>\n",
    "link": "https://stackoverflow.com/questions/78192016/cannot-upload-app-py-to-huggingface-space"
  },
  {
    "question": "AttributeError: &#39;VectorStoreIndex&#39; object has no attribute &#39;documents&#39;",
    "answer": "<p>I ran into the same error, trying to build my chatbot refined on custom data. I implemented this code: <a href=\"https://docs.kanaries.net/tutorials/ChatGPT/how-to-train-chatgpt\" rel=\"nofollow noreferrer\">https://docs.kanaries.net/tutorials/ChatGPT/how-to-train-chatgpt</a></p>\n<p>To be honest, I think it is just stolen from somewhere else, because the article has been posted in July, yet much of the code turned out to be deprecated for a long time (months, years).</p>\n<p>I &quot;worked around&quot; the load_index_from_storage() issue, based on Andrew Arrow's answer. I am not reading the indices after saving them, but just keeping them in memory (I know, dirty).</p>\n<p>You can do that by modifying the create_index() function to return the index, and calling it before defining the chat interface.</p>\n<p>I then run into another error, namely, <code>AttributeError: 'VectorStoreIndex' object has no attribute 'query'</code>. I see that you are using the same call, so you may encounter an error too.<br />\nThe solution to that was provided by VirajOke in this thread: <a href=\"https://github.com/jerryjliu/llama_index/issues/2497\" rel=\"nofollow noreferrer\">https://github.com/jerryjliu/llama_index/issues/2497</a></p>\n<p>I will post my full code below, I just tested it and it works. Hope this helps. :)</p>\n<pre><code>import os\nfrom langchain import OpenAI\nimport openai\nimport gradio as gr\nimport sys\nkey = 'your_api_key' # it's important to set the key before importing llama_index, as the library does not update environmental variables once loaded   \nopenai.api_key = key\nos.environ[&quot;OPENAI_API_KEY&quot;] = key\nfrom llama_index import SimpleDirectoryReader, GPTListIndex, GPTVectorStoreIndex, LLMPredictor, PromptHelper, load_index_from_storage\n\n    \n \ndef construct_index(directory_path):\n    max_input_size = 4096\n    num_outputs = 512\n    max_chunk_overlap = 0.1 #20\n    chunk_size_limit = 600\n\n    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.7, model_name=&quot;gpt-3.5-turbo&quot;, max_tokens=num_outputs))\n    documents = SimpleDirectoryReader(directory_path).load_data()\n    index = GPTVectorStoreIndex(documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n    index.storage_context.persist(persist_dir=&quot;index.json&quot;)\n    return index\n\nindex = construct_index(&quot;docs&quot;)\n\ndef chatbot(input_text):\n    query_engine = index.as_query_engine()\n    response = query_engine.query(input_text)\n    return response.response\n \niface = gr.Interface(fn=chatbot,\n                     inputs=gr.inputs.Textbox(lines=7, label=&quot;Enter your text&quot;),\n                     outputs=&quot;text&quot;,\n                     title=&quot;My AI Chatbot&quot;)\n \niface.launch(share=True)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76771313/attributeerror-vectorstoreindex-object-has-no-attribute-documents"
  },
  {
    "question": "Limitation of building a simple AWS-based app on Gradio",
    "answer": "<ol>\n<li>Gradio</li>\n</ol>\n<ul>\n<li><p>You can certainly do some authentication (either basic or oauth). This page has both <a href=\"https://www.gradio.app/guides/sharing-your-app#o-auth-login-via-hugging-face\" rel=\"nofollow noreferrer\">Gradio Authentication</a>.</p>\n</li>\n<li><p>I found this example for integrating gradio with s3 buckets. <a href=\"https://modal.com/docs/examples/cloud_bucket_mount_loras\" rel=\"nofollow noreferrer\">https://modal.com/docs/examples/cloud_bucket_mount_loras</a></p>\n</li>\n</ul>\n<ol start=\"2\">\n<li>Flask</li>\n</ol>\n<ul>\n<li><p>Flask and basic html are quite easy (even with only minimal python experience). <a href=\"https://palletsprojects.com/p/flask/\" rel=\"nofollow noreferrer\">Flask</a> took very little time to grasp.</p>\n</li>\n<li><p>It also supports auth (Basic and OAuth). <a href=\"https://marketsplash.com/tutorials/flask/how-to-implement-flask-oauth/\" rel=\"nofollow noreferrer\">Flask Oauth</a></p>\n</li>\n<li><p>Here's a sample (without auth) I <a href=\"https://github.com/asutermo/TheConversationSentimentAnalysis/blob/main/app/main.py\" rel=\"nofollow noreferrer\">wrote</a> that uses Quart (an async version of flask) to showcase how easy it is to build. I'm not a frontend person. The sample renders templates (html) and fills them with basic information.</p>\n</li>\n</ul>\n<p>You'll definitely be able to do everything you need with Flask relatively easily.</p>\n",
    "link": "https://stackoverflow.com/questions/77885514/limitation-of-building-a-simple-aws-based-app-on-gradio"
  },
  {
    "question": "I can&#39;t use the Gradio Client API to make a prediction using images",
    "answer": "<p>I was facing a similar issue, there might be some problem on what kind of data you are sending to the api endpoint of &quot;/predict&quot; through exampleImage, still looking to solve this error. You can also try to check the container logs in huggingface spaces of your deployed model.</p>\n",
    "link": "https://stackoverflow.com/questions/78176532/i-cant-use-the-gradio-client-api-to-make-a-prediction-using-images"
  },
  {
    "question": "How to access or save the image generated by gradio_client on python",
    "answer": "<p>Pls use matplotlib and PIL:</p>\n<pre><code>image = Image.open(result)\nplt.imshow(image)\nplt.axis('off')  \nplt.show()\nimage.save(&quot;output_image.png&quot;)\n</code></pre>\n<p><strong>Sample code:</strong></p>\n<pre><code>from gradio_client import Client\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nclient = Client(&quot;ByteDance/SDXL-Lightning&quot;)\nresult = client.predict(\n        &quot;astronaut riding a horse realistic&quot;,   \n        &quot;8-Step&quot;,   \n        api_name=&quot;/generate_image&quot;\n)\n\nimage = Image.open(result)\nplt.imshow(image)\nplt.axis('off')  \nplt.show()\nimage.save(&quot;output_image.png&quot;)\n</code></pre>\n<p><strong>Output:</strong></p>\n<p><a href=\"https://i.sstatic.net/KotRa.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/KotRa.png\" alt=\"enter image description here\" /></a></p>\n",
    "link": "https://stackoverflow.com/questions/78160138/how-to-access-or-save-the-image-generated-by-gradio-client-on-python"
  },
  {
    "question": "How to toggle visibility of a Gradio component based on radio button?",
    "answer": "<p>Solution:</p>\n<pre><code>import gradio as gr\n\nwith gr.Blocks() as demo:\n\n    radio = gr.Radio([&quot;show&quot;, &quot;hide&quot;], label=&quot;Choose&quot;)\n    text = gr.Textbox(label=&quot;This text only shows when 'show' is selected.&quot;, visible=False)\n\n    \n    def update_visibility(radio):  # Accept the event argument, even if not used\n        value = radio  # Get the selected value from the radio button\n        if value == &quot;show&quot;:\n            return gr.Textbox(visible=bool(1)) #make it visible\n        else:\n            return gr.Textbox(visible=bool(0))]\n    radio.change(update_visibility, radio, text)\n\ndemo.launch()\n</code></pre>\n<p>If it doesn't work you can try to return with the update function: gr.Textbox.update(visible=bool(1))</p>\n",
    "link": "https://stackoverflow.com/questions/77976715/how-to-toggle-visibility-of-a-gradio-component-based-on-radio-button"
  },
  {
    "question": "How can I have the value of a Gradio block be passed to a function&#39;s named parameter?",
    "answer": "<p>As far as I know, Gradio doesn't directly allow it. I.e., it doesn't allow something like this:</p>\n<pre><code>btn.click(fn=dummy, inputs={&quot;a&quot;: txt, &quot;c&quot;: txt2}, outputs=answer)\n</code></pre>\n<p>In this specific case, if you can't modify the <code>dummy</code> function then I would rearrange the parameters with the following function:</p>\n<pre><code>def rearrange_args(func):\n    def wrapper(*args):\n        a, c = args\n        return func(a, c=c)\n    return wrapper\n</code></pre>\n<p>Now, you just need to modify your example as follows:</p>\n<pre><code>btn.click(rearrange_args(dummy), inputs=[txt, txt2], outputs=[answer])\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/78073286/how-can-i-have-the-value-of-a-gradio-block-be-passed-to-a-functions-named-param"
  },
  {
    "question": "gradio HTML component with javascript code don&#39;t work",
    "answer": "<p>just use html code as string in python\nlike this</p>\n<pre class=\"lang-py prettyprint-override\"><code>htmlStr = '''&lt;html&gt;\n  &lt;body&gt;\n\n      &lt;script type = &quot;text/JavaScript&quot;&gt;\n        function test() {\n          document.getElementById('demo').innerHTML = &quot;Hello&quot;\n          }\n      &lt;/script&gt;\n\n    &lt;h1&gt;My First JavaScript&lt;/h1&gt;\n    &lt;button type=&quot;testButton&quot; onclick=&quot;test()&quot;&gt; Start &lt;/button&gt;\n\n    &lt;p id=&quot;demo&quot;&gt;&lt;/p&gt;\n\n  &lt;/body&gt;\n&lt;/html&gt;'''\n\n...\ninput_mic = gr.HTML(lines)\n...\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76071586/gradio-html-component-with-javascript-code-dont-work"
  },
  {
    "question": "How can one add a label to a Markdown box in Gradio?",
    "answer": "<p><a href=\"https://twitter.com/yvrjsharma\" rel=\"nofollow noreferrer\">yuvi</a> posted this <a href=\"https://discord.com/channels/879548962464493619/1025174734427656283/threads/1205659532051750972\" rel=\"nofollow noreferrer\">great answer</a> on Discord:</p>\n<blockquote>\n<p><code>label</code> doesn't work the same way for <code>gr.HTML</code> and <code>gr.markdown</code> as it does for other components.\nExample for intended use of the label param  in both these components :</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\nwith gr.Blocks() as demo:\n    answerhtml = gr.HTML(value='''&lt;a href='https://hf.co//'&gt;huggingface&lt;/a&gt;''', label=&quot;Answer HTML&quot;)\n    answer = gr.Markdown(value='[gradio](https://gradio.app/)', label=&quot;Answer Markdown&quot;)\n\n    gr.Examples([\n        ['[StackOverflow](https://stackoverflow.com/)', '''&lt;a href='https://stackoverflow.com/'&gt;stackoverflow&lt;/a&gt;'''],\n        ['[google](https://google.com/)', '''&lt;a href='https://google.com/'&gt;google&lt;/a&gt;''']\n    ], [answer, answerhtml])\ndemo.launch(share=True)\n</code></pre>\n<p>Here, you'll see that the labels for these two are used as headers for the example table below your app:</p>\n<p><a href=\"https://i.sstatic.net/yvQ5J.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/yvQ5J.png\" alt=\"enter image description here\" /></a></p>\n<p>One way to add a label could be to encase the markdown in an gr.Accordion and keep it open by default:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\nwith gr.Blocks() as demo:\n  with gr.Accordion('Answers:', open=True):\n    answerhtml = gr.HTML(value='''&lt;a href='https://hf.co//'&gt;huggingface&lt;/a&gt;''', label=&quot;Answer HTML&quot;)\n    answer = gr.Markdown(value='[gradio](https://gradio.app/)', label=&quot;Answer Markdown&quot;)\n\n  gr.Examples([\n        ['[StackOverflow](https://stackoverflow.com/)', '''&lt;a href='https://stackoverflow.com/'&gt;stackoverflow&lt;/a&gt;'''],\n        ['[google](https://google.com/)', '''&lt;a href='https://google.com/'&gt;google&lt;/a&gt;''']\n    ], [answer, answerhtml])\ndemo.launch(share=True)\n</code></pre>\n<p>What else you can do is add headings as h1/h2/h3 tags within an HTML component or use hashtags within your markdown examples.</p>\n<p><a href=\"https://i.sstatic.net/7KUgz.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/7KUgz.png\" alt=\"enter image description here\" /></a></p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\nval = '''&lt;h1&gt;Answers&lt;/h1&gt;\n'''\nwith gr.Blocks() as demo:\n    heading = gr.HTML(value=val)\n    answerhtml = gr.HTML(value='''&lt;a href='https://hf.co//'&gt;huggingface&lt;/a&gt;''', label=&quot;Answer HTML&quot;)\n    answer = gr.Markdown(value='[gradio](https://gradio.app/)', label=&quot;Answer Markdown&quot;)\n\n    gr.Examples([\n        ['[StackOverflow](https://stackoverflow.com/)', '''&lt;a href='https://stackoverflow.com/'&gt;stackoverflow&lt;/a&gt;'''],\n        ['[google](https://google.com/)', '''&lt;a href='https://google.com/'&gt;google&lt;/a&gt;''']\n    ], [answer, answerhtml])\ndemo.launch(share=True)\n</code></pre>\n<p><a href=\"https://i.sstatic.net/s5AwD.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/s5AwD.png\" alt=\"enter image description here\" /></a></p>\n</blockquote>\n<p>Based on that answer, I replaced:</p>\n<pre><code>import gradio as gr\nwith gr.Blocks(css=&quot;footer{display:none !important}&quot;) as demo:\n    answer = gr.Markdown(value='[StackOverflow](https://stackoverflow.com/)', label=&quot;Answer&quot;)\ndemo.launch()\n</code></pre>\n<p>with</p>\n<pre><code>import gradio as gr\nwith gr.Blocks(css=&quot;footer{display:none !important}&quot;) as demo:\n    with gr.Accordion('Answer:', open=True):\n        answer = gr.Markdown(value='[StackOverflow](https://stackoverflow.com/)', label=&quot;&quot;)\ndemo.launch()\n</code></pre>\n<p>which gives:</p>\n<p><a href=\"https://i.sstatic.net/W1fcu.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/W1fcu.png\" alt=\"enter image description here\" /></a></p>\n",
    "link": "https://stackoverflow.com/questions/77971348/how-can-one-add-a-label-to-a-markdown-box-in-gradio"
  },
  {
    "question": "Use Start/Stop button to record live audio using Gradio app",
    "answer": "<p>I was able to figure out a solution. Hope it helps! You can also find it <a href=\"https://discuss.huggingface.co/t/use-start-stop-button-to-record-live-audio-using-gradio-app/53313\" rel=\"nofollow noreferrer\">here</a>.</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\n\n\ndef click_js():\n    return &quot;&quot;&quot;function audioRecord() {\n    var xPathRes = document.evaluate ('//*[@id=&quot;audio&quot;]//button', document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null); \n    xPathRes.singleNodeValue.click();}&quot;&quot;&quot;\n\n\ndef action(btn):\n    &quot;&quot;&quot;Changes button text on click&quot;&quot;&quot;\n    if btn == 'Speak': return 'Stop'\n    else: return 'Speak'\n\n\ndef check_btn(btn):\n    &quot;&quot;&quot;Checks for correct button text before invoking transcribe()&quot;&quot;&quot;\n    if btn != 'Speak': raise Exception('Recording...')\n\n\ndef transcribe():\n    return 'Success'\n\n\nwith gr.Blocks() as demo:\n    msg = gr.Textbox()\n    audio_box = gr.Audio(label=&quot;Audio&quot;, source=&quot;microphone&quot;, type=&quot;filepath&quot;, elem_id='audio')\n\n    with gr.Row():\n        audio_btn = gr.Button('Speak')\n        clear = gr.Button(&quot;Clear&quot;)\n\n    audio_btn.click(fn=action, inputs=audio_btn, outputs=audio_btn).\\\n      then(fn=lambda: None, _js=click_js()).\\\n      then(fn=check_btn, inputs=audio_btn).\\\n      success(fn=transcribe, outputs=msg)\n\nclear.click(lambda: None, None, msg, queue=False)\n\ndemo.queue().launch(debug=True)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/77025043/use-start-stop-button-to-record-live-audio-using-gradio-app"
  },
  {
    "question": "How to stream Agent&#39;s response in Langchain?",
    "answer": "<p>One of possible solutions is to use a queue as a mediator.</p>\n<ol>\n<li>Create a queue</li>\n</ol>\n<pre class=\"lang-py prettyprint-override\"><code>from queue import SimpleQueue\nq = SimpleQueue()\n</code></pre>\n<ol start=\"2\">\n<li>Create a custom callback, that will write produced tokens into the queue</li>\n</ol>\n<pre class=\"lang-py prettyprint-override\"><code>from langchain.callbacks.base import BaseCallbackHandler\nfrom langchain.schema import LLMResult\nfrom typing import Any, Union\n\n\njob_done = object() # signals the processing is done\n\nclass StreamingGradioCallbackHandler(BaseCallbackHandler):\n    def __init__(self, q: SimpleQueue):\n        self.q = q\n\n    def on_llm_start(\n        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n    ) -&gt; None:\n        &quot;&quot;&quot;Run when LLM starts running. Clean the queue.&quot;&quot;&quot;\n        while not self.q.empty():\n            try:\n                self.q.get(block=False)\n            except Empty:\n                continue\n\n    def on_llm_new_token(self, token: str, **kwargs: Any) -&gt; None:\n        &quot;&quot;&quot;Run on new LLM token. Only available when streaming is enabled.&quot;&quot;&quot;\n        self.q.put(token)\n\n    def on_llm_end(self, response: LLMResult, **kwargs: Any) -&gt; None:\n        &quot;&quot;&quot;Run when LLM ends running.&quot;&quot;&quot;\n        self.q.put(job_done)\n\n    def on_llm_error(\n        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any\n    ) -&gt; None:\n        &quot;&quot;&quot;Run when LLM errors.&quot;&quot;&quot;\n        self.q.put(job_done)\n</code></pre>\n<ol start=\"3\">\n<li>Give the callback to your LLM</li>\n</ol>\n<pre class=\"lang-py prettyprint-override\"><code>callback_manager=CallbackManager([StreamingGradioCallbackHandler(q),\n                                  StreamingStdOutCallbackHandler()]), \n</code></pre>\n<ol start=\"4\">\n<li>In Gradio code, create a parallel thread, that will run your agent. Read from the queue.</li>\n</ol>\n<p>I don't understand your ChatWrapper. Actually, I am not familiar with Gradio, so I will rely on an example from the <a href=\"https://gradio.app/creating-a-chatbot/#add-streaming-to-your-chatbot\" rel=\"noreferrer\">documentation</a>.</p>\n<pre class=\"lang-py prettyprint-override\"><code>from threading import Thread\n\ndef bot(history):\n    user_question = history[-1][0]\n    thread = Thread(target=chain.run, kwargs={&quot;input&quot;: user_question})\n    thread.start()\n    history[-1][1] = &quot;&quot;\n    while True:\n        next_token = q.get(block=True) # Blocks until an input is available\n        if next_token is job_done:\n            break\n        history[-1][1] += next_token\n        yield history\n    thread.join()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76057076/how-to-stream-agents-response-in-langchain"
  },
  {
    "question": "Gradio - remove the tagline",
    "answer": "<p>You can access the footer via css and make it hidden:</p>\n<pre class=\"lang-css prettyprint-override\"><code>footer {visibility: hidden}\n</code></pre>\n<p>Used in the following hello world example, makes &quot;built with gradio&quot; hidden.</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\n\ndef greet(name):\n    return &quot;Hello &quot; + name + &quot;!&quot;\n\ndemo = gr.Interface(\n    fn=greet,\n    inputs=&quot;text&quot;,\n    outputs=&quot;text&quot;,\n    css=&quot;footer {visibility: hidden}&quot;\n)\ndemo.launch()\n\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/72960397/gradio-remove-the-tagline"
  },
  {
    "question": "How can I move a button before a box that the button uses or changes in Gradio?",
    "answer": "<p>You can <a href=\"https://www.gradio.app/docs/clearbutton#event-listeners\" rel=\"nofollow noreferrer\">add the components of clear button</a> after initialization. This way, you are able to decouple the component creation order:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\n\n\ndef dummy(a):\n    return &quot;hello&quot;, {&quot;hell&quot;: &quot;o&quot;}\n\n\nwith gr.Blocks() as demo:\n    txt = gr.Textbox(value=&quot;test&quot;, label=&quot;Query&quot;, lines=1)\n    answer = gr.Textbox(value=&quot;&quot;, label=&quot;Answer&quot;)\n    btn = gr.Button(value=&quot;Submit&quot;)\n    clear_btn = gr.ClearButton()\n    answerjson = gr.JSON()\n    \n    btn.click(dummy, inputs=[txt], outputs=[answer, answerjson])\n    clear_btn.add([answer, answerjson])\n\ndemo.launch(share=True)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/77959301/how-can-i-move-a-button-before-a-box-that-the-button-uses-or-changes-in-gradio"
  },
  {
    "question": "How to get selected text from Gradio Texbox?",
    "answer": "<p>See &quot;Gathering Event Data&quot; in this: <a href=\"https://www.gradio.app/guides/blocks-and-event-listeners#gathering-event-data\" rel=\"nofollow noreferrer\">https://www.gradio.app/guides/blocks-and-event-listeners#gathering-event-data</a></p>\n",
    "link": "https://stackoverflow.com/questions/76747453/how-to-get-selected-text-from-gradio-texbox"
  },
  {
    "question": "Gradio app triggers event listener second time after 60 minutes",
    "answer": "<p>I still don‚Äôt quite understand exactly why this behaviour occurs, but I‚Äôve found out that calling Gradio‚Äôs <code>.queue()</code> function (see <a href=\"https://www.gradio.app/docs/blocks#blocks-queue\" rel=\"nofollow noreferrer\">https://www.gradio.app/docs/blocks#blocks-queue</a> for <code>gradio.Blocks()</code> and <a href=\"https://www.gradio.app/docs/interface#interface-queue\" rel=\"nofollow noreferrer\">https://www.gradio.app/docs/interface#interface-queue</a> for <code>gradio.Interface()</code>) has solved the problem.</p>\n",
    "link": "https://stackoverflow.com/questions/77859801/gradio-app-triggers-event-listener-second-time-after-60-minutes"
  },
  {
    "question": "Load new content within loop in Gradio upon button click",
    "answer": "<p>I solved it. The main idea is to create as many markdown blocks as the maximum number of turns in a conversation, and set the ones beyond the number of turns in a given conversation to be invisible. A bit tricky (and probably some unnecessary parts) but here is the code:</p>\n<pre><code>import gradio as gr\nimport random\nimport json\n\nconversation_data = [\n    {\n        'conv_id': '8e271b9985994065bec97e2fdc7b4139',\n        'transcript': [\n            {'speaker': 'Human', 'response': &quot;What kind of noises did dinosaurs make?&quot;},\n            {'speaker': 'Assistant',\n             'response': &quot;Humans and dinosaurs didn‚Äôt live at the same time, so it‚Äôs really hard to say.&quot;},\n            {'speaker': 'Human', 'response': 'yes they did'},\n            {'speaker': 'Assistant',\n             'response': &quot;to guess, and that would probably require lots of reading and a certain amount of imagination, so we‚Äôre not really prepared to do that. &quot;},\n            {'speaker': 'Human', 'response': 'you cant read'},\n            {'speaker': 'Assistant', 'response': &quot;there‚Äôs a lot of stuff humans don‚Äôt know&quot;}\n        ]\n    },\n    {\n        'conv_id': '4e341c9235194065bec97e2fdc7b4139',\n        'transcript': [\n            {'speaker': 'Human', 'response': &quot;How much time do you spend with your family?&quot;},\n            {'speaker': 'Assistant',\n             'response': &quot;Since I am not a person, I am unable to understand the question, I am not sure how to answer it.&quot;},\n        ]\n    },\n]\n\nmax_conversation_length = max([len(conversation['transcript']) for conversation in conversation_data])\n\ncheckbox_choices = [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;]\n\n\ndef get_conversation():\n    conv = random.choice(conversation_data)\n    return conv\n\n\ndef pad_transcript(transcript, max_length):\n    padding_count = max_length - len(transcript)\n    if padding_count &gt; 0:\n        for _ in range(padding_count):\n            transcript.append({'speaker': '', 'response': ''})\n    return transcript\n\n\ndef submit(*args):\n    conv_id = args[0]\n    markdown_blocks = list(args[1:-2])\n    labels = args[-2]\n\n    data = {'conv_id': conv_id, 'labels': labels}\n    with open(f&quot;./labels/conv_{conv_id}&quot;, 'w') as f:\n        json.dump(data, f, indent=4)\n\n    new_conversation = get_conversation()\n    new_conv_id = new_conversation['conv_id']\n    new_transcript = pad_transcript(new_conversation['transcript'], max_conversation_length)\n\n    for i in range(max_conversation_length):\n        if new_transcript[i]['speaker'] != '':\n            markdown_blocks[i] = gr.Markdown(f&quot;&quot;&quot;&lt;br&gt;**{new_transcript[i]['speaker']}**: {new_transcript[i]['response']}&quot;&quot;&quot;,\n                                             visible=True)\n        else:\n            markdown_blocks[i] = gr.Markdown(&quot;&quot;, visible=False)\n\n    new_labels = gr.CheckboxGroup(choices=checkbox_choices,\n                                  label=&quot;&quot;,\n                                  visible=False)\n    conv_len = gr.Number(value=len(new_transcript), visible=False)\n\n    return [new_conv_id] + list(markdown_blocks) + [labels] + [new_labels] + [conv_len]\n\n\nconversation = get_conversation()\n\nwith gr.Blocks() as interface:\n    conv_id = conversation['conv_id']\n    transcript = conversation['transcript']\n    conv_len = gr.Number(value=len(transcript), visible=False)\n    padded_transcript = pad_transcript(transcript, max_conversation_length)\n\n    markdown_blocks = [None] * max_conversation_length\n    with gr.Column(scale=1, min_width=600):\n        for i in range(max_conversation_length):\n            markdown_blocks[i] = gr.Markdown(f&quot;&quot;&quot;&lt;br&gt;**{padded_transcript[i]['speaker']}**: {padded_transcript[i]['response']}&quot;&quot;&quot;,\n                                         visible=True)\n            if i &gt;= conv_len.value:\n                markdown_blocks[i].visible = False\n        checkboxes = gr.CheckboxGroup(choices=checkbox_choices, label=&quot;&quot;)\n\n    submit_button = gr.Button(&quot;Submit&quot;)\n\n    conv_id_element = gr.Text(value=conv_id, visible=False)\n    input_list = [conv_id_element] + markdown_blocks + [checkboxes] + [conv_len]\n    submit_button.click(\n        fn=submit,\n        inputs=input_list,\n        outputs=[conv_id_element, *markdown_blocks, checkboxes, conv_len]\n    )\n\ninterface.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/77892867/load-new-content-within-loop-in-gradio-upon-button-click"
  },
  {
    "question": "huggingface expected input format",
    "answer": "<p>In case it helps someone: the correct format seems to be: { &quot;data&quot;: [&quot;John&quot;] }</p>\n<pre><code>curl -d '{ &quot;data&quot;:  [&quot;John&quot;]}' -H &quot;Content-Type: application/json&quot; -X POST https://toromanow-test2.hf.space/api/predict\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76223210/huggingface-expected-input-format"
  },
  {
    "question": "UI issue while adding Gemini API using Gradio",
    "answer": "<p>We have to only return the output from here not the tuple - please go through the disucussion in <a href=\"https://github.com/gradio-app/gradio/issues/6881\" rel=\"nofollow noreferrer\">https://github.com/gradio-app/gradio/issues/6881</a> . It actually resolved the issue.</p>\n",
    "link": "https://stackoverflow.com/questions/77715622/ui-issue-while-adding-gemini-api-using-gradio"
  },
  {
    "question": "Whenever I submit the first query, I always get an &quot;error&quot; with Gradio. But subsequent queries work fine. Why?",
    "answer": "<p>Created a new env in anaconda, installed <code>python 3.8.18</code>, it worked for me</p>\n",
    "link": "https://stackoverflow.com/questions/77363447/whenever-i-submit-the-first-query-i-always-get-an-error-with-gradio-but-subs"
  },
  {
    "question": "Is there a way to link gradio interfaces through webpages?",
    "answer": "<p>I think you can use global variables to link between the interfaces, as well as you can use beside it another library like webbrowser to open the url of other interfaces</p>\n",
    "link": "https://stackoverflow.com/questions/76870442/is-there-a-way-to-link-gradio-interfaces-through-webpages"
  },
  {
    "question": "chatgpt api streaming asynchronously in gradio chatInterface",
    "answer": "<p>I solved this problem with this! Thank you!</p>\n<pre><code>stream = await client.chat.completions.create(\n        model=&quot;gpt-4&quot;,\n        messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: input_text}],\n        stream=True,\n)\n    partial_message = &quot;&quot;\n    async for chunk in stream:\n        if chunk.choices[0].delta.content is not None :\n            partial_message = partial_message + chunk.choices[0].delta.content\n            yield partial_message\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/77683852/chatgpt-api-streaming-asynchronously-in-gradio-chatinterface"
  },
  {
    "question": "How to cutomize the gradio app interface and tigger a function based on output of first interface?",
    "answer": "<p>To achieve the desired functionality of triggering function2 based on the output of function1 within a single Gradio interface, you can use the live option in Gradio. The live option allows you to update the state of the interface based on the output of a previous component.</p>\n<pre><code>import gradio as gr\n\n# Define your functions\ndef listen_audio(input1):\n    # Your code here\n    return 'hello'\n\ndef create_ticket(output_of_listen_audio_function):\n    # Your code here\n    return 'Your ticket has been created üèÜ'\n\n# Create the Gradio interface\ndemo = gr.Interface(fn=listen_audio, \n                    inputs=gr.Audio(sources=&quot;microphone&quot;, type=&quot;filepath&quot;), \n                    outputs=&quot;text&quot;,\n                    live=True)  # Set live to True to enable dynamic updates\n\n# Add a component for creating a ticket\ndemo.add_component(component=create_ticket, \n                   inputs=[&quot;checkbox&quot;], \n                   outputs=&quot;text&quot;,\n                   live=True,  # Set live to True for dynamic updates\n                   live_inputs=[0])  # Specify the index of the input to be updated dynamically\n\n# Launch the Gradio interface\ndemo.launch()\n</code></pre>\n<p>In this example, I've set live=True for both components. The live_inputs parameter is used to specify which input should trigger a live update. In this case, live_inputs=[0] indicates that the output of the first component should trigger a live update for the second component.</p>\n<p>Now, when you run the interface, the output of listen_audio will dynamically update the input of create_ticket, allowing you to trigger function2 based on the output of function1 within a single interface.</p>\n",
    "link": "https://stackoverflow.com/questions/77646355/how-to-cutomize-the-gradio-app-interface-and-tigger-a-function-based-on-output-o"
  },
  {
    "question": "Welcome message in python chatbot using gradio and openAI API",
    "answer": "<p>Use gr.Chatbot and set the value parameter as illustrated below.</p>\n<p><code>gr.ChatInterface(fn=respond, chatbot=gr.Chatbot(value=[(None, &quot;Welcome üëã. I am an assistant&quot;)],),)</code></p>\n",
    "link": "https://stackoverflow.com/questions/76416674/welcome-message-in-python-chatbot-using-gradio-and-openai-api"
  },
  {
    "question": "How to update Video component in gradio?",
    "answer": "<p>Running your code, uploading an <code>.mp4</code> video file and clicking on the <code>Update</code> button results in the following exception:</p>\n<pre><code>AttributeError: type object 'Video' has no attribute 'update'\n</code></pre>\n<p>This is most likely because you are using a recent version of Gradio. In Gradio 4.0, the <code>update()</code> method was removed (see <a href=\"https://www.gradio.app/changelog#:%7E:text=Removes%20the%20deprecated%20.update()%20method%20from%20component%20classes\" rel=\"nofollow noreferrer\">Gradio 4.0 changelog</a>)</p>\n<hr />\n<h2>Updating Components</h2>\n<p>The recommended way for updating components is now to <a href=\"https://www.gradio.app/guides/blocks-and-event-listeners#updating-component-configurations\" rel=\"nofollow noreferrer\">have your event listener function return the updated value of the corresponding output Component</a>. This might not really be necessary for your use case though. For the full details, check out the <code>Passing Input Into a Component Normally</code> section of this answer.</p>\n<p>Modifying your code to accomodate the reccomended method of updating Gradio components:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import shutil\nimport gradio as gr\n\ndef update_video(input_video):\n    old_video_path = input_video\n    new_video_path = input_video.replace('.mp4', '_out.mp4')\n\n    # Replace shutil.copyfile with whatever processing you are doing\n    shutil.copyfile(old_video_path, new_video_path)\n\n    # Return the updated video component. \n    # You only need to specify in the arguments the things you wish to\n    # change. In this case we're only interested in the `value` but \n    # it can also be `label`, `scale`, `visibility` et cetera\n    return gr.Video(value=new_video_path)\n\nwith gr.Blocks(theme=gr.themes.Soft()) as interface:\n    # gr.components.Video is equivalent to gr.Video\n    inputs = gr.Video()\n    update = gr.Button('Update')\n\n    update.click(update_video, inputs=inputs, outputs=[inputs])\n\ninterface.launch(height=700)\n</code></pre>\n<p>Just make sure that as you're modifying the path of the video file, the new path points to a valid video file that can be played.</p>\n<hr />\n<h2>Passing Input Into a Component Normally</h2>\n<p>However, in the first place, you don't actually need to explicitly update the <code>gr.Video</code> component.</p>\n<p>In the <code>update.click</code> event listener, you are already passing the output of the <code>update_video</code> event listener function into the <code>inputs</code> <code>gr.Video</code> component.</p>\n<pre class=\"lang-py prettyprint-override\"><code>update.click(\n    update_video, # The event listener function\n    inputs=inputs, # Where inputs into `update_video` come from\n    outputs=[inputs] # Where output from `update_video` will go.\n                     # It can be either be what the `inputs` `gr.Video` \n                     # component expects as input, or it can be an \n                     # update for the `inputs` `gr.Video` component\n)\n\n</code></pre>\n<p>Because of that, you'll be able to replicate the same behaviour as above by just retuning the modified filepath in your <code>update_video</code> event listener function like so:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import shutil\nimport gradio as gr\n\ndef update_video(input_video):\n    old_video_path = input_video\n    new_video_path = input_video.replace('.mp4', '_out.mp4')\n\n    # Replace shutil.copyfile with whatever processing you are doing\n    shutil.copyfile(old_video_path, new_video_path)\n\n    # Simply return the new video path\n    return new_video_path\n\nwith gr.Blocks(theme=gr.themes.Soft()) as interface:\n    # gr.components.Video is equivalent to gr.Video\n    inputs = gr.Video()\n    update = gr.Button('Update')\n\n    update.click(update_video, inputs=inputs, outputs=[inputs])\n\ninterface.launch(height=700)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76256533/how-to-update-video-component-in-gradio"
  },
  {
    "question": "How to create a Dropdown based on other choices in Python library Gradio",
    "answer": "<p>This worked for me. I'm using gradio 4.4.0</p>\n<pre><code>import gradio as gr\n\noptions_1 = ['Paris', 'Berlin' ]\noptions_2 = {\n    'Paris': ['Saint Denis', 'Eiffel Tower', 'Le Louvre'],\n    'Berlin': ['Reichstag', 'Alexanderplatz', 'Kreuzberg'],\n    }\n\nwith gr.Blocks() as demo:\n    d1 = gr.Dropdown(choices=options_1, label=&quot;City dropdown&quot;)\n    d2 = gr.Dropdown([])\n    \n    def update_second(first_val):\n        d2 = gr.Dropdown(options_2[first_val])\n        return d2 \n    \n    d1.input(update_second, d1, d2)\n\n    outputs = gr.Textbox()\n\n    def print_results(option_1, option_2):\n        return f&quot;You selected '{option_1}' in the first dropdown and '{option_2}' in the second dropdown.&quot;\n        \n    d2.input(print_results, [d1, d2], outputs) \n\ndemo.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/75008502/how-to-create-a-dropdown-based-on-other-choices-in-python-library-gradio"
  },
  {
    "question": "How can I change some properties of a textbox when created with gr.Interface?",
    "answer": "<p>I just discovered <a href=\"/questions/tagged/gradio\" class=\"post-tag\" title=\"show questions tagged &#39;gradio&#39;\" aria-label=\"show questions tagged &#39;gradio&#39;\" rel=\"tag\" aria-labelledby=\"tag-gradio-tooltip-container\">gradio</a> but seems like the <code>outputs</code> parameter accepts any <code>IOComponent</code> (<em>like a</em> <a href=\"https://www.gradio.app/docs/textbox\" rel=\"nofollow noreferrer\"><code>Textbox</code></a>) as an argument :</p>\n<pre><code>import gradio as gr\n\ndef greet(name):\n    return &quot;Hello &quot; + name + &quot;!&quot;\n        \ndemo = gr.Interface(\n    fn=greet,\n    inputs=&quot;text&quot;,\n    outputs=gr.Textbox(max_lines=3, autoscroll=False)\n)\n\ndemo.launch()\n</code></pre>\n<p><em>NB: In the demo below, I'm shadowing your <code>greet</code> function to make a default long input text.</em></p>\n<p><a href=\"https://i.sstatic.net/eRWmA.gif\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/eRWmA.gif\" alt=\"enter image description here\" /></a></p>\n",
    "link": "https://stackoverflow.com/questions/77269875/how-can-i-change-some-properties-of-a-textbox-when-created-with-gr-interface"
  },
  {
    "question": "Gradio HTML component display mounted on FAST API",
    "answer": "<p>The function has to be called by gradio which only happens if you pass it as callable to a gradio Component, or call it yourself using <code>get_user_info(request)</code>.</p>\n<p>One way to do it is to use the gradio <code>Blocks.load</code> instance method:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\nfrom fastapi import FastAPI\nfrom starlette.middleware.sessions import SessionMiddleware\nimport uuid\n\napp = FastAPI()\n\ndef get_user_info(request: gr.Request):\n    return  f&quot;&lt;b&gt;Welcome {request.request.session.get('username', 'User')}!&lt;b/&gt;&quot;\n\nwith gr.Blocks(title=&quot;test&quot;) as demo:\n    gr.Markdown(&quot;# Test App&quot;)\n    with gr.Row():\n        with gr.Column():\n            user_info = gr.components.HTML()\n    demo.load(get_user_info, outputs=user_info)\n\napp = gr.mount_gradio_app(app, demo, &quot;/home&quot;)\napp.add_middleware(SessionMiddleware, secret_key=uuid.uuid4().hex)\n\n# to launch this example standalone:\n# \n# if __name__ == '__main__':\n#     import uvicorn\n#     uvicorn.run(app, host='127.0.0.1', port=8007)\n\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/77195870/gradio-html-component-display-mounted-on-fast-api"
  },
  {
    "question": "Integrating Gradio/Streamlit with Flask for Multi-Model Hosting and Route Customization",
    "answer": "<p>This is an interesting idea to integrate several low-code web frameworks together.</p>\n<p>Aside from the aforementioned <code>iframe</code> approach, flask's <code>render_template</code> may be a possible route but given that Streamlit apps is not static and is interactive in nature where the app reruns when interactive widgets are altered, this may not be feasible. Aside from this, Streamlit is an inherent web framework on itself that is based on the Tornado web framework and may have other rabbit holes to explore further (<a href=\"https://stackoverflow.com/questions/70114207/can-a-streamlit-app-be-run-within-a-flask-app\">see this related Stack Overflow post</a> for more info).</p>\n<p>Sam Minot has written a great article in Towards Data Science (<a href=\"https://towardsdatascience.com/python-based-data-viz-with-no-installation-required-aaf2358c881\" rel=\"nofollow noreferrer\">Python-Based Data Viz (With No Installation Required</a>) showing a use case of embedding a Streamlit app in an HTML file using <a href=\"https://github.com/whitphx/stlite\" rel=\"nofollow noreferrer\"><code>stlite</code></a> that is based on Web Assembly (a project that allows Python code to run inside a web browser) and powered by Pyodide.</p>\n<p>Here's an example of Sam's embedding of a Streamlit app in an HTML file hosted on GitHub:\n<a href=\"https://i.sstatic.net/TN6TR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/TN6TR.png\" alt=\"Image from Sam Minot's blog\" /></a></p>\n<p>Additionally, here's the <a href=\"https://github.com/FredHutch/stlite-template/blob/main/index.html\" rel=\"nofollow noreferrer\">code snippet</a> of the above mentioned HTML file in Sam's blog:</p>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta charset=&quot;UTF-8&quot; /&gt;\n    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;\n    &lt;meta\n      name=&quot;viewport&quot;\n      content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;\n    /&gt;\n    &lt;title&gt;stlite app&lt;/title&gt;\n    &lt;link\n      rel=&quot;stylesheet&quot;\n      href=&quot;https://cdn.jsdelivr.net/npm/@stlite/mountable@0.7.1/build/stlite.css&quot;\n    /&gt;\n    &lt;style&gt;\n      footer {        \n        visibility: hidden;\n      }\n      footer:after {\n        content:'Based on github.com/FredHutch/stlite-template'; \n        visibility: visible;\n        display: block;\n        position: relative;\n        padding: 5px;\n        top: 2px;\n      }\n    &lt;/style&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div id=&quot;root&quot;&gt;&lt;/div&gt;\n    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/@stlite/mountable@0.7.1/build/stlite.js&quot;&gt;&lt;/script&gt;\n    &lt;script&gt;\n        fetch(&quot;app.py&quot;)\n            .then((response) =&gt; response.text())\n            .then(\n                (app) =&gt; stlite.mount(\n                    {\n                        requirements: [&quot;click&quot;, &quot;scipy&quot;, &quot;plotly&quot;],\n                        entrypoint: &quot;app.py&quot;,\n                        files: {\n                            &quot;app.py&quot;: app\n                        }\n                    },\n                    document.getElementById(&quot;root&quot;)\n                )\n            );\n    &lt;/script&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<p>Another route to explore could be <a href=\"https://pyscript.net/\" rel=\"nofollow noreferrer\">pyscript</a> (similar in concept with the above mentioned <code>stlite</code>) which allows Python to run in an HTML file.</p>\n<p>Further ideas and information in venturing into this path could also be found in prior discussions in the Streamlit forum:</p>\n<ul>\n<li><a href=\"https://discuss.streamlit.io/t/serve-streamlit-within-flask/493\" rel=\"nofollow noreferrer\">https://discuss.streamlit.io/t/serve-streamlit-within-flask/493</a></li>\n<li><a href=\"https://discuss.streamlit.io/t/integration-with-flask-app/809\" rel=\"nofollow noreferrer\">https://discuss.streamlit.io/t/integration-with-flask-app/809</a></li>\n</ul>\n<p>Hope this helps!</p>\n",
    "link": "https://stackoverflow.com/questions/77155566/integrating-gradio-streamlit-with-flask-for-multi-model-hosting-and-route-custom"
  },
  {
    "question": "build and deploy docker container to build fast api app on Azure web app",
    "answer": "<ul>\n<li>Here I created Azure ML workspace and navigate to the &quot;Notebooks&quot; section and create a new Python 3.8-based notebook.</li>\n</ul>\n<p><img src=\"https://i.imgur.com/VBa8n6L.png\" alt=\"enter image description here\" /></p>\n<p><strong>Dockerfile file:</strong></p>\n<pre class=\"lang-yaml prettyprint-override\"><code># Use the official Python image from Docker Hub\nFROM python:3.8-slim\n\n# Set the working directory to /app\nWORKDIR /app\n\n# Copy the current directory contents into the container at /app\nCOPY . /app\n\n# Install any dependencies\nRUN pip install -r requirements.txt\n\n# Expose port 8501 for Streamlit\nEXPOSE 8501\n\n# Run the Streamlit app\nCMD [&quot;streamlit&quot;, &quot;run&quot;, &quot;testlikeapro.py&quot;]\n</code></pre>\n<ul>\n<li>In my script I have <strong>streamlit</strong> dependencies so, I created <a href=\"https://i.imgur.com/nUtZuY6.png\" rel=\"nofollow noreferrer\">requirement.txt</a> file in the same directory as Dockerfile existed.</li>\n</ul>\n<p>Then build the docker image using <code>!docker build -t your-image-name:tag .</code></p>\n<p><img src=\"https://i.imgur.com/Ls6ItE0.png\" alt=\"enter image description here\" /></p>\n<p>I am able to see the docker image in below.</p>\n<p><img src=\"https://i.imgur.com/xFAaCW8.png\" alt=\"enter image description here\" /></p>\n<p>Then <a href=\"https://i.imgur.com/6sZXMvK.png\" rel=\"nofollow noreferrer\">Login</a> into Azure Container Registry using <code>az acr login --name your-Acr-name</code></p>\n<ul>\n<li>Again build the image for you ACR using <code>docker build -t your-Acr-name.azurecr.io/belikepro:latest .</code></li>\n</ul>\n<p><img src=\"https://i.imgur.com/Z1JWcnV.png\" alt=\"enter image description here\" /></p>\n<p>Successfully the image is pushed into ACR <a href=\"https://i.imgur.com/5UlziYA.png\" rel=\"nofollow noreferrer\">registries</a>.</p>\n<ul>\n<li>Then create a web application and configured the Docker container settings in the <a href=\"https://i.imgur.com/0rQMBvP.png\" rel=\"nofollow noreferrer\">App Service</a> to point to the ACR image.</li>\n</ul>\n<p><img src=\"https://i.imgur.com/ek7CV1p.png\" alt=\"enter image description here\" /></p>\n<p><strong>Result:</strong></p>\n<p><img src=\"https://i.imgur.com/poAHpBU.png\" alt=\"enter image description here\" /></p>\n",
    "link": "https://stackoverflow.com/questions/77136418/build-and-deploy-docker-container-to-build-fast-api-app-on-azure-web-app"
  },
  {
    "question": "Starting Python Gradio app in Azure App Service",
    "answer": "<p>This the way I managed to solve this issue:\nI didn't find any solution lo launch Gradio directly with an Azure startup command ( on my laptop a simple &quot;python app.py&quot; works). I replaced then the gradio &quot;launch()&quot; by &quot;mount_gradio_app()&quot; method to start the application in a FastAPI app.\n<a href=\"https://www.gradio.app/docs/mount_gradio_app\" rel=\"nofollow noreferrer\">https://www.gradio.app/docs/mount_gradio_app</a>\nIt seems it is because only python web application running on Gunicorn or Unicorn web server can be started in an Azure App Service.\nBut I don't have a clear documentation on that , so this is only my assumption.\nHope It helps.\nThank you</p>\n",
    "link": "https://stackoverflow.com/questions/77050499/starting-python-gradio-app-in-azure-app-service"
  },
  {
    "question": "Cannot record with a Gradio audio input using dynamic layout",
    "answer": "<p>Adding a component solely to <code>outputs</code> makes it <code>interactive=False</code> by default.\nAdd your audio component to <code>inputs</code> to make it work:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio\n\nwith gradio.Blocks() as interface:\n    recorder = gradio.Audio(source='microphone', type='filepath', visible=False)\n    action_btn = gradio.Button('Start')\n    def next_line(action, _):\n        if action == 'Start':\n            return {action_btn: 'Next', recorder: gradio.update(visible=True)}\n        else:\n            return {action_btn: 'Done', recorder: gradio.update(visible=False)}\n    action_btn.click(next_line, inputs=[action_btn, recorder], outputs=[action_btn, recorder])\ninterface.launch(share=True)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/75846512/cannot-record-with-a-gradio-audio-input-using-dynamic-layout"
  },
  {
    "question": "json error is occuring when i executing the code in google collab in python",
    "answer": "<p>I got the same error from my local machine. And the code</p>\n<p><code>export no_proxy=&quot;localhost, 127.0.0.1&quot;</code> helps me.</p>\n",
    "link": "https://stackoverflow.com/questions/76817423/json-error-is-occuring-when-i-executing-the-code-in-google-collab-in-python"
  },
  {
    "question": "What is the gradio version for using encode_url_or_file_to_base64",
    "answer": "<p><code>encode_url_or_file_to_base64</code> function move to <code>gradio_client.utils</code></p>\n<p>so, use it like this:</p>\n<pre><code>import gradio as gr\nimport gradio.utils as gr_utils\nfrom gradio_client import utils as client_utils\n\ndef audio_postprocess(self, y):\n    data = audio_postprocess_ori(self, y)\n    if data is None:\n        return None\n    return client_utils.encode_url_or_file_to_base64(data[&quot;name&quot;])\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76648919/what-is-the-gradio-version-for-using-encode-url-or-file-to-base64"
  },
  {
    "question": "How can I use a self made tensorflow CNN model in a gradio app?",
    "answer": "<p>First of all. You're saving model, not model_2 here:</p>\n<pre><code># Save model 2\nmodel.save(&quot;mnist_model.h5&quot;)\n</code></pre>\n<p>When you run the code it should give you an error.</p>\n<p>Second, I would assume that the reason for an error is that the image you're giving the model is a usual png image which have 3 channels (R/G/B), but you're training the model with 1 channel (see input_shape(28, 28, <strong>1</strong>)</p>\n<pre><code>tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n</code></pre>\n<p>You need to convert your test image to grayscale image(which has 1 channel not 3) and it should work fine</p>\n",
    "link": "https://stackoverflow.com/questions/76929003/how-can-i-use-a-self-made-tensorflow-cnn-model-in-a-gradio-app"
  },
  {
    "question": "Gradio on Sagemaker Studio Lab",
    "answer": "<p>While I am not sure of what example you are using have you tried:</p>\n<p><code>Use inline=False and server_port=6006.</code></p>\n<pre><code>gr.Interface(\n    fn=infer,\n    title=&quot;Monocular Depth Estimation&quot;,\n    description = &quot;Keras Implementation of Unet architecture with Densenet201 backbone for estimating the depth of image üìè&quot;,\n    inputs=[gr.inputs.Image(label=&quot;image&quot;, type=&quot;numpy&quot;, shape=(640, 480))],\n    outputs=&quot;image&quot;,\n    article = &quot;Author: &lt;a href=\\&quot;https://huggingface.co/vumichien\\&quot;&gt;Vu Minh Chien&lt;/a&gt;. Based on the Keras example from &lt;a href=\\&quot;https://keras.io/examples/vision/depth_estimation/\\&quot;&gt;Victor Basu&lt;/a&gt;. Repo: https://github.com/machinelearnear/use-gradio-streamlit-sagemaker-studiolab&quot;,\n    examples=examples).launch(inline=False, server_port=6006, debug=True, cache_examples=True)\n\n</code></pre>\n<p><a href=\"https://github.com/machinelearnear/use-gradio-streamlit-sagemaker-studiolab\" rel=\"nofollow noreferrer\">https://github.com/machinelearnear/use-gradio-streamlit-sagemaker-studiolab</a></p>\n",
    "link": "https://stackoverflow.com/questions/76823778/gradio-on-sagemaker-studio-lab"
  },
  {
    "question": "How to Use the Gradio Javascript Client",
    "answer": "<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=&quot;en&quot;&gt;\n&lt;head&gt;\n    &lt;meta charset=&quot;UTF-8&quot;&gt;\n    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt;\n    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;\n    &lt;title&gt;Prompt Generator&lt;/title&gt;\n    &lt;style&gt;\n        body {\n            text-align: center;\n            background-color:whitesmoke;\n          }\n\n        #phrase {\n            padding: 15px;\n            width: 20%;\n            border: 5px solid rgb(49, 47, 68);\n            text-align: center;\n        }\n\n        #prompt-holder {\n            width: 50%;\n            height: 50%;\n            margin: 0 auto;\n            border: 5px solid rgb(50, 31, 221);\n            padding: 20px;\n            text-align: center;\n            background-color:rgb(246, 247, 248)\n    }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h3&gt;&lt;strong&gt;AI Text-To-Image Prompt Generator&lt;/strong&gt;&lt;/h3&gt;\n    &lt;br&gt;&lt;br&gt;\n    &lt;div id=&quot;text-input&quot;&gt;&lt;input type=&quot;text&quot; title=&quot;Starting Phrase&quot; id=&quot;phrase&quot; placeholder=&quot;Enter phrase here&quot;&gt;&lt;/div&gt;\n    &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;\n    &lt;button id=&quot;run&quot;&gt;&lt;strong&gt;Generate Prompt&lt;/strong&gt;&lt;/button&gt;\n    &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;\n    &lt;div id=&quot;prompt-holder&quot;&gt;&lt;/div&gt;\n&lt;/body&gt;\n\n&lt;script type=&quot;module&quot; src=&quot;https://cdn.jsdelivr.net/npm/@gradio/client@0.1.4/dist/index.min.js&quot;&gt;&lt;/script&gt;\n&lt;script type=&quot;module&quot;&gt;\n    import { client } from &quot;https://cdn.jsdelivr.net/npm/@gradio/client@0.1.4/dist/index.min.js&quot;;\n    const inputText = document.getElementById(&quot;phrase&quot;);\n    const generate = document.getElementById(&quot;run&quot;);\n    const prompt_holder = document.getElementById(&quot;prompt-holder&quot;);\n\n    generate.addEventListener(&quot;click&quot;, async () =&gt;{\n        try {\n            const textInput = inputText.value;\n\n            const app = await client(&quot;https://ifeanyi-promptgenerator.hf.space/&quot;);\n            const result = await app.predict(&quot;/predict&quot;, [      \n            textInput, // string  in 'prompt' Textbox component\n        ]);\n            prompt_holder.textContent = result.data;            \n\n            } catch (error){\n                 console.log(&quot;Error:&quot;,error.message);         \n            }\n    \n        }\n\n        \n);\n&lt;/script&gt;\n&lt;/html&gt;\n</code></pre>\n<p>here is your project on static HTML</p>\n",
    "link": "https://stackoverflow.com/questions/76806819/how-to-use-the-gradio-javascript-client"
  },
  {
    "question": "ValueError: Invalid message for Chatbot component: (message)",
    "answer": "<p>I've worked it out - I had to change one line as follows:</p>\n<pre><code>response = str(query_engine.query(message))\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76795397/valueerror-invalid-message-for-chatbot-component-message"
  },
  {
    "question": "SD Automatic 1111: src/tcmalloc.cc:283] Attempt to free invalid pointer 0x5a3426b059d0",
    "answer": "<p>I removed this line of code, and the UI started loading for me again:</p>\n<pre><code>%env LD_PRELOAD=libtcmalloc.so\n</code></pre>\n<p><strong>EDIT:</strong> Just saw there's a discussion about this going on Git:\n<a href=\"https://github.com/TheLastBen/fast-stable-diffusion/issues/2343\" rel=\"nofollow noreferrer\">https://github.com/TheLastBen/fast-stable-diffusion/issues/2343</a></p>\n<p>Looks like additionally updating this code in the Requirements snippet is making it work for some:</p>\n<pre><code>!pip install --no-cache-dir open-clip-torch==2.20.0 -qq --no-deps\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76725813/sd-automatic-1111-src-tcmalloc-cc283-attempt-to-free-invalid-pointer-0x5a3426"
  },
  {
    "question": "Download huggingface table / DataFrame?",
    "answer": "<p>The Open LLM leaderboard dataset has been made public as a dataset <a href=\"https://huggingface.co/datasets/open-llm-leaderboard/results\" rel=\"nofollow noreferrer\">here</a>, and can be manipulated using the <code>datasets</code> library or downloaded using <code>git</code>.</p>\n<p>Have fun with the data!</p>\n<p>(Disclaimer: I'm one of the leaderboard's programmers/researchers.)</p>\n",
    "link": "https://stackoverflow.com/questions/76421521/download-huggingface-table-dataframe"
  },
  {
    "question": "Gradio Interface does not output anything",
    "answer": "<p>Since it works outside of the gradio interface,\nHow about make &quot;prompter.prompt_model_print(emo_name_prompts)&quot; part a function\nand call it in gradio interface?</p>\n",
    "link": "https://stackoverflow.com/questions/76320182/gradio-interface-does-not-output-anything"
  },
  {
    "question": "Gradio convert to API",
    "answer": "<p>Gradio supports session state, where data persists across multiple submits within a page load. Session state is useful for building demos of, for example, chatbots where you want to persist data as the user interacts with the model. Note that session state does not share data between different users of your model.</p>\n<p>To store data in a session state, you need to do three things:</p>\n<p>Pass in an extra parameter into your function, which represents the state of the interface.\nAt the end of the function, return the updated value of the state as an extra return value.\nAdd the ‚Äòstate‚Äô input and ‚Äòstate‚Äô output components when creating your Interface.\nSee the chatbot example below:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import random\n\nimport gradio as gr\n\n\ndef chat(message, history):\n    history = history or []\n    if message.startswith(&quot;How many&quot;):\n        response = random.randint(1, 10)\n    elif message.startswith(&quot;How&quot;):\n        response = random.choice([&quot;Great&quot;, &quot;Good&quot;, &quot;Okay&quot;, &quot;Bad&quot;])\n    elif message.startswith(&quot;Where&quot;):\n        response = random.choice([&quot;Here&quot;, &quot;There&quot;, &quot;Somewhere&quot;])\n    else:\n        response = &quot;I don't know&quot;\n    history.append((message, response))\n    return history, history\n\n\niface = gr.Interface(\n    chat,\n    [&quot;text&quot;, &quot;state&quot;],\n    [&quot;chatbot&quot;, &quot;state&quot;],\n    allow_screenshot=False,\n    allow_flagging=&quot;never&quot;,\n)\niface.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76508701/gradio-convert-to-api"
  },
  {
    "question": "How to View Result Image from Output String in Gradio API",
    "answer": "<p>The path <code>/tmp/gradio/e7c2ab46e69f6712e387aa71344ee7a6b9848d67/tmplyvg8rd5.png</code> doesn't refer to a URL segment, but rather to a file on the filesystem. You can view it by either directly opening the file (you can find it using the Google Colab file explorer), or you can display it in the notebook using any popular Python image visualization library.</p>\n<p>Here is a minimal working example using the popular <code>Pillow</code>, which you can install <code>pip install Pillow</code>.</p>\n<pre><code>from gradio_client import Client\nfrom PIL import Image\n\n# Create a client and specify the API URL\nclient = Client(&quot;https://huggingface-projects-qr-code-ai-art-generator--58b6vlwzv.hf.space/&quot;)\n\n# Make a prediction\nresult = client.predict(\n    &quot;https://my-url-here.com&quot;,      # str  in 'QR Code Content' Textbox component\n    &quot;red bus&quot;,                 # str  in 'Prompt' Textbox component\n    &quot;blue&quot;,                    # str  in 'Negative Prompt' Textbox component\n    1,                         # int | float (numeric value between 0.0 and 50.0) in 'Guidance Scale' Slider component\n    1,                         # int | float (numeric value between 0.0 and 5.0) in 'Controlnet Conditioning Scale' Slider component\n    0.9,                       # int | float (numeric value between 0.0 and 1.0) in 'Strength' Slider component\n    -1,                        # int | float (numeric value between -1 and 9999999999) in 'Seed' Slider component\n    &quot;https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png&quot;,    # str (filepath or URL to image) in 'Init Image (Optional). Leave blank to generate image with SD 2.1' Image component\n    &quot;https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png&quot;,    # str (filepath or URL to image) in 'QR Code Image (Optional). Leave blank to automatically generate QR code' Image component\n    True,                      # bool  in 'Use QR code as init image' Checkbox component\n    &quot;DPM++ Karras SDE&quot;,        # str (Option from: ['DPM++ Karras SDE', 'DPM++ Karras', 'Heun', 'Euler', 'DDIM', 'DEIS']) in 'Sampler' Dropdown component\n    fn_index=0\n)\n\n# View the image\nImage.open(result)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76616794/how-to-view-result-image-from-output-string-in-gradio-api"
  },
  {
    "question": "How do I remedy this attributeerror in terminal while trying to execute a gradio interface?",
    "answer": "<p>Check your Python file name, if it's <code>gradio.py</code> rename it to something else</p>\n",
    "link": "https://stackoverflow.com/questions/75880531/how-do-i-remedy-this-attributeerror-in-terminal-while-trying-to-execute-a-gradio"
  },
  {
    "question": "How can i reload the page in gradio?",
    "answer": "<p>Try this</p>\n<pre><code>btn_refresh = gr.Button(value=&quot;Refresh the page&quot;)\nbtn_refresh.click(None, _js=&quot;window.location.reload()&quot;)\n</code></pre>\n<p>This is going to create a button and when it's clicked the page will get reloaded</p>\n",
    "link": "https://stackoverflow.com/questions/76027764/how-can-i-reload-the-page-in-gradio"
  },
  {
    "question": "How to call function when &quot;stop recording&quot; button pressed?",
    "answer": "<p><code>Audio</code> objects have <code>stop_recording</code> event listeners, so in your case <code>stream_input.stop_recording(stop_streaming)</code> should work.</p>\n<p>For more complicated use cases, you will probably need to call your function <em>after</em> the <code>stop_recording</code> call, e.g. <code>stream_input.stop_recording(lambda: None).then(stop_streaming)</code>.</p>\n",
    "link": "https://stackoverflow.com/questions/76146483/how-to-call-function-when-stop-recording-button-pressed"
  },
  {
    "question": "Share is not supported when you are in Spaces. Gradio&amp;Hugging face&#39;s Spaces",
    "answer": "<p>You just need to disable sharing feature\n<code>intf.launch(inline=True)</code></p>\n",
    "link": "https://stackoverflow.com/questions/75197492/share-is-not-supported-when-you-are-in-spaces-gradiohugging-faces-spaces"
  },
  {
    "question": "Issues while using @gradio/client in Next JS,",
    "answer": "<p>make the corresponding change in next.config.js will resolve the issue.</p>\n<p>I see the following three source to get this answer:</p>\n<p><a href=\"https://nextjs.org/docs/app/api-reference/next-config-js/webpack\" rel=\"nofollow noreferrer\">https://nextjs.org/docs/app/api-reference/next-config-js/webpack</a></p>\n<p><a href=\"https://stackoverflow.com/questions/72133210/react-unhandledschemeerror-nodebuffer-is-not-handled-by-plugins\">React UnhandledSchemeError - &quot;node:buffer&quot; is not handled by plugins</a></p>\n<p><a href=\"https://github.com/getsentry/sentry-javascript/issues/6548\" rel=\"nofollow noreferrer\">https://github.com/getsentry/sentry-javascript/issues/6548</a></p>\n<pre><code>const {webpack} = require(&quot;next/dist/compiled/webpack/webpack&quot;);\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n    // output: 'export',\n    // Optional: Add a trailing slash to all paths `/about` -&gt; `/about/`\n    // trailingSlash: true,\n    // Optional: Change the output directory `out` -&gt; `dist`\n    // distDir: 'dist',\n    webpack: (config, {isServer}) =&gt; {\n        if (!isServer) {\n            config.resolve = {\n                ...config.resolve,\n                fallback: {\n                    // fixes proxy-agent dependencies\n                    net: false,\n                    dns: false,\n                    tls: false,\n                    assert: false,\n                    // fixes next-i18next dependencies\n                    path: false,\n                    fs: false,\n                    // fixes mapbox dependencies\n                    events: false,\n                    // fixes sentry dependencies\n                    process: false\n                }\n            };\n        }\n        config.plugins.push(new webpack.NormalModuleReplacementPlugin(/node:/, (resource) =&gt; {\n            resource.request = resource.request.replace(/^node:/, &quot;&quot;);\n        }))\n\n        return config\n    },\n    experimental: {appDir: true}\n};\n\nmodule.exports = nextConfig\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76500464/issues-while-using-gradio-client-in-next-js"
  },
  {
    "question": "GRADIO: Change position of second slider, when value lower than on first one",
    "answer": "<p>Ok, I found solution using Gradio Box:</p>\n<pre><code>def compare(number1, number2):\n    if number1 &gt; number2:\n        number2 = number1\n    return number2\n\n\ndef add_function(number1, number2):\n    return number2 + number1\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            slider1 = gr.Slider(0, 100, default=50, label=&quot;number1&quot;, interactive=True)\n            slider2 = gr.Slider(0, 100, default=50, label=&quot;number2&quot;, interactive=True)\n        with gr.Column():\n            predict = gr.Button()\n            output = gr.Number(label=&quot;output&quot;)\n\n    slider1.change(compare, [slider1, slider2], slider2)\n    click_event = predict.click(add_function, [slider1, slider2] , output)\n\ndemo.queue().launch()\n</code></pre>\n<p>Not so fast, but solve my problem :)</p>\n",
    "link": "https://stackoverflow.com/questions/75523914/gradio-change-position-of-second-slider-when-value-lower-than-on-first-one"
  },
  {
    "question": "Blocks from gradio package unable to receive a custmized function that reads the csv or excel file",
    "answer": "<p>If we use <code>gr.Interface</code> instead of insisting on <code>gr.Blocks</code>, the following code will work:</p>\n<pre><code>import gradio as gr\nimport csv\nimport pandas as pd\n\ndef read_excel_file(file_path):\n    if file_path.name.endswith('.csv'):\n        data = pd.read_csv(file_path.name)\n    elif file_path.name.endswith('.xlsx') or file_path.name.endswith('.xls'):\n        data = pd.read_excel(file_path.name)\n    else:\n        raise ValueError('File type not supported. Please provide a CSV or Excel file.')\n    return data\n\nfile_input = gr.inputs.File(label=&quot;Upload Excel File&quot;)\noutput = gr.outputs.Dataframe(type='pandas')\n\ninterface = gr.Interface(fn=read_excel_file, inputs=file_input, outputs=output)\ninterface.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76494998/blocks-from-gradio-package-unable-to-receive-a-custmized-function-that-reads-the"
  },
  {
    "question": "How to fix `transformers` package not found error in a Python project with `py-langchain`, `llama-index`, and `gradio`?",
    "answer": "<p>Maybe you can uncomment</p>\n<pre><code>##from transformers import pipeline\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76378059/how-to-fix-transformers-package-not-found-error-in-a-python-project-with-py-l"
  },
  {
    "question": "How can I get current text from TextArea in Gradio",
    "answer": "<p>If you click a button you can pass the value as an input. For example</p>\n<pre><code>import gradio as gr\ninput1 = gr.TextArea(label=&quot;Text (100 words max)&quot;, value=example,\n                                                             elem_id=f&quot;input{i}&quot;)\nbtn = gr.Button(value=&quot;Submit&quot;)\nbtn.click(combine, inputs=[input1])\n\ndef combine(input1):\n    print(input1)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/75181125/how-can-i-get-current-text-from-textarea-in-gradio"
  },
  {
    "question": "Move up example block in gradio",
    "answer": "<p>You should try to use the Block method instead. You can find it <a href=\"https://gradio.app/docs/#block-layouts\" rel=\"nofollow noreferrer\">here</a>. It's very easy to do what you want if you use this method's components.</p>\n",
    "link": "https://stackoverflow.com/questions/76004989/move-up-example-block-in-gradio"
  },
  {
    "question": "Gradio - Print response of bot with animated characters appearing one by one like chatGPT answers",
    "answer": "<p>I think I found a solution:</p>\n<pre><code>    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n    while True: \n        response = index.query(question, response_mode=&quot;compact&quot;)        \n        messages.append({&quot;User asks&quot;: question, &quot;System response&quot;: response.response.strip()})\n        #return response.response.strip()\n        for el in range(1):\n            history = []\n            for el in response.response.strip():\n                history.append(el)\n                word = ''.join(history)\n                time.sleep(0.02)\n                yield str(word)\n        break```\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76430904/gradio-print-response-of-bot-with-animated-characters-appearing-one-by-one-lik"
  },
  {
    "question": "SSLError ( certificate verify failed)",
    "answer": "<p>I assume that you use a self-signed certificate?</p>\n<p>The problem is that when you use a self-signed certificate, SSL verification fails.\nYou can disable verification by adding a <code>ssl_verify=False</code> parameter when launching.</p>\n<pre class=\"lang-py prettyprint-override\"><code>demo.queue().launch(share=False,\n                        debug=False,\n                        server_name=&quot;0.0.0.0&quot;,\n                        server_port=8432,\n                        ssl_certfile=&quot;/home/user/cert.pem&quot;,\n                        ssl_keyfile=&quot;/home/user/key.pem&quot;,\n                        ssl_verify=False\n)\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/76130037/sslerror-certificate-verify-failed"
  },
  {
    "question": "Cant resolve Import exception in python using Visual Studio Code",
    "answer": "<p>You need to make sure that interpreter used by VS Code matches one you are using in the terminal. In the environment you installed python in type: <code>which python</code> (or <code>which python3</code>, depending on your setup.</p>\n<p>Then follow <a href=\"https://code.visualstudio.com/docs/python/environments#_working-with-python-interpreters\" rel=\"nofollow noreferrer\">these instructions</a> and select the path that matches output of the command above.</p>\n<p>Lastly, I highly recommend setting up per-project environments (see: <a href=\"https://mamba.readthedocs.io/en/latest/index.html\" rel=\"nofollow noreferrer\">Mamba</a>, <a href=\"https://docs.conda.io/en/latest/\" rel=\"nofollow noreferrer\">Conda</a>, or <a href=\"https://python-poetry.org/\" rel=\"nofollow noreferrer\">Poetry</a> all accomplishing the similar goals in slightly different ways)</p>\n",
    "link": "https://stackoverflow.com/questions/76348441/cant-resolve-import-exception-in-python-using-visual-studio-code"
  },
  {
    "question": "How to specify constant inputs for Gradio click handler?",
    "answer": "<p>If you want a constant number input which is not visible on the UI you can pass <code>gr.Number(value=2, visible=False)</code></p>\n",
    "link": "https://stackoverflow.com/questions/75965051/how-to-specify-constant-inputs-for-gradio-click-handler"
  },
  {
    "question": "How to add question and GPT Api response variables to Gradio chatbot()?",
    "answer": "<p>I made it work. This is the solution:</p>\n<pre><code>from IPython.display import Markdown, display\nfrom llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain import OpenAI\nimport gradio as gr\nimport random, time\nimport sys\nimport os\n\nos.environ[&quot;OPENAI_API_KEY&quot;] = '' #insert your key there\n\ndef construct_index(directory_path):\n    global index\n    # set maximum input size\n    max_input_size = 4096\n    # set number of output tokens\n    num_outputs = 500\n    # set maximum chunk overlap\n    max_chunk_overlap = 20\n    # set chunk size limit\n    chunk_size_limit = 600 \n\n    llm_predictor = LLMPredictor(llm = ChatOpenAI(temperature=0.1, model_name='gpt-3.5-turbo', max_tokens=num_outputs)) #original temp was .5\n    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n \n    documents = SimpleDirectoryReader(directory_path).load_data()\n    global index\n    index = GPTSimpleVectorIndex(\n        documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n    index.save_to_disk('index.json')\n    return index\n\nconstruct_index(&quot;context_data/data/done&quot;)\n\n#Define chat function\ndef chat(chat_history, user_input):\n      index = GPTSimpleVectorIndex.load_from_disk('index.json')\n      bot_response = index.query(user_input)\n      response = &quot;&quot;\n      for letter in ''.join(bot_response.response): #[bot_response[i:i+1] for i in range(0, len(bot_response), 1)]:\n          response += letter + &quot;&quot;\n          yield chat_history + [(user_input, response.strip())]\n     \n#Build interface\nwith gr.Blocks() as demo:\n    with gr.Tab('Chat with this helpful AI assistant'):\n          chatbot = gr.Chatbot()\n          message = gr.Textbox (label = 'Write your message here and press &quot;enter&quot;')\n          message.submit(chat, [chatbot, message], chatbot).then(lambda: None, None, message, queue=False)\n\ndemo.queue().launch(debug = True, share = True)\n     \n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/75897729/how-to-add-question-and-gpt-api-response-variables-to-gradio-chatbot"
  },
  {
    "question": "How do I use Gradio blocks as variables that can be used in a local function?",
    "answer": "<p>The problem of your code are the commas after the component definitions for example:</p>\n<pre class=\"lang-py prettyprint-override\"><code>age = gr.Number(label=&quot;Age&quot;), #1 Age\n</code></pre>\n<p>As those are normal python variable declarations, commas are not supposed to be there removing them everywhere where necessary makes your code working fine:</p>\n<pre class=\"lang-py prettyprint-override\"><code>age = gr.Number(label=&quot;Age&quot;) #1 Age\n</code></pre>\n<p>The reason for this is that commas automatically create a tuple:</p>\n<pre class=\"lang-py prettyprint-override\"><code>a = 3,\nprint(type(a))\n\n&gt;&gt;&gt; &lt;class 'tuple'&gt;\n</code></pre>\n<p>contrary to</p>\n<pre class=\"lang-py prettyprint-override\"><code>a = 3\nprint(type(a))\n\n&gt;&gt;&gt; &lt;class 'int'&gt;\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/75816904/how-do-i-use-gradio-blocks-as-variables-that-can-be-used-in-a-local-function"
  },
  {
    "question": "How do I refresh a gradio button after pressing submit?",
    "answer": "<p>Such behavior is only possible using the Blocks Layout, as you somehow need to update the input component. Here is an example:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\n\ncounter = 1\n\ndef generate_output(input_text):\n    global counter\n    output_text = &quot;Hello, &quot; + input_text + &quot;!&quot;\n    counter += 1\n    return output_text, gr.Textbox.update(label=f&quot;Question {counter}&quot;)\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n    \n        # column for inputs\n        with gr.Column():\n            input_text = gr.Textbox(label=&quot;Input Text&quot;)\n            submit_button = gr.Button(&quot;Submit&quot;)\n                   \n        # column for outputs\n        with gr.Column():\n            output_text = gr.Textbox()\n            \n    submit_button.click(\n        fn=generate_output,\n        inputs=input_text,\n        outputs=[output_text, input_text]\n    )\n\ndemo.launch()\n</code></pre>\n<p>Here, the input text component is also passed to <code>outputs</code> and then updated in the <code>generate_output</code> function using <code>gr.update</code>. You could do this too with using gr.Interface, but this would result in the Textbox being displayd also on the output side.</p>\n<p>Note, that there also is a <a href=\"https://gradio.app/docs/#chatbot\" rel=\"nofollow noreferrer\">Chatbot Component</a> for Gradio!</p>\n",
    "link": "https://stackoverflow.com/questions/75776198/how-do-i-refresh-a-gradio-button-after-pressing-submit"
  },
  {
    "question": "I am trying to open a gradio program using a tkinter button, the function is being called but it does not open in on a browser",
    "answer": "<p>Just set the <code>inbrowser</code> option to <code>True</code> when launching the interface:</p>\n<pre class=\"lang-py prettyprint-override\"><code>def run_gradio():\n    iface.launch(inbrowser=True)\n</code></pre>\n<p>This <em>automatically launches the interface in a new tab on the default browser.</em></p>\n",
    "link": "https://stackoverflow.com/questions/75802995/i-am-trying-to-open-a-gradio-program-using-a-tkinter-button-the-function-is-bei"
  },
  {
    "question": "Configure FastAPI app hosted on hreoku to use HTTPS",
    "answer": "<p>This is not Uvicorn's responsibility.</p>\n<p>If you are using the default <code>your-app.herokuapp.com</code> domain, or if you are using Basic- or Professional-tier dynos, HTTPS should already be available.</p>\n<p>If you are using a custom domain with Eco dynos, the easiest solution¬π is to upgrade to <a href=\"https://devcenter.heroku.com/articles/automated-certificate-management#common-runtime\" rel=\"nofollow noreferrer\">upgrade to Basic</a> dynos to get access to <a href=\"https://devcenter.heroku.com/articles/automated-certificate-management\" rel=\"nofollow noreferrer\">automated certificate management</a> (ACM), which uses <a href=\"https://letsencrypt.org/\" rel=\"nofollow noreferrer\">Let's Encrypt</a> under the hood:</p>\n<blockquote>\n<p>If your app is currently running on eco dynos, Heroku enables ACM automatically when you upgrade your app to use Basic or Professional dynos:</p>\n<pre><code>heroku ps:resize web=basic\n</code></pre>\n</blockquote>\n<p>Once HTTPS is <em>available</em>, you may want to configure a redirect from HTTP to HTTPS. Heroku does not do this for you. Referencing the Flask Security Guide, <a href=\"https://help.heroku.com/J2R1S4T8/can-heroku-force-an-application-to-use-ssl-tls\" rel=\"nofollow noreferrer\">Heroku recommends</a> using <a href=\"https://github.com/GoogleCloudPlatform/flask-talisman\" rel=\"nofollow noreferrer\"><code>flask-talisman</code></a> for this. Out of the box, <code>flask-talisman</code> configures several security-related bast practices, including a redirect from HTTP to HTTPS.</p>\n<hr />\n<p>¬πIf you don't want to do this, your other option is to provide your own certificate via <a href=\"https://devcenter.heroku.com/articles/ssl\" rel=\"nofollow noreferrer\">Heroku SSL</a>. This is more work, and since you have to provide your own certificate can come with significant financial cost.</p>\n",
    "link": "https://stackoverflow.com/questions/75704155/configure-fastapi-app-hosted-on-hreoku-to-use-https"
  },
  {
    "question": "Gradio ouputs keys of a dictionary instead of strings while using openai.ChatCompletion API and GPT-3.5-turbo",
    "answer": "<p>Okay, solved it. The issue was that history is a dictionary. The output of the submit wanted a list of lists. I finally solved it by creating a separate list. The list list of questions and reply, then the next item on the top most list is another list of question and reply.</p>\n<p>Dictionaries are the death of me. Here is the fixed code.</p>\n<pre><code>chat_history = []\n\ndef gpt_reply(chat_history):\n    response = openai.ChatCompletion.create(\n        model=&quot;gpt-3.5-turbo&quot;,\n        messages=chat_history)\n    reply = response[&quot;choices&quot;][0][&quot;message&quot;][&quot;content&quot;]\n    return reply\n\n\ndef predict(input, history = []):\n    if len(history) == 0:\n        system_msg = &quot;You are an expert code completionist.&quot;\n        history.append({&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_msg})\n        with open(&quot;chatbot.txt&quot;, &quot;w&quot;) as f:\n            f.write(&quot;System: &quot;+system_msg)\n    if len(history) &gt; 10:\n        history.pop(1)\n        history.pop(2)\n        history.pop(3)\n    \n    message = input\n    with open(&quot;chatbot.txt&quot;, &quot;a&quot;) as f:\n        f.write(&quot;\\nUser: &quot; + message + &quot;\\n&quot;)\n    history.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: message})\n    reply = gpt_reply(history)\n    history.append({&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: reply})\n    with open(&quot;chatbot.json&quot;, &quot;w&quot;) as f:\n        json.dump(history, f, indent=4, ensure_ascii=False)\n    # create new list with only the user and bot responses. Each response is a string of one item of a list\n    chat_history.append([message, reply])\n    with open(&quot;user_responses.json&quot;, &quot;w&quot;) as f:\n        json.dump(chat_history, f, indent=4, ensure_ascii=False)\n    return chat_history, history\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    state = gr.State([])\n    \n    with gr.Row():\n        txt = gr.Textbox(show_label=False, placeholder=&quot;What kind of chatbot would you like to create? &quot;).style(container=False)\n    \n    txt.submit(predict, [txt, state], [chatbot, state])\n\ndemo.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/75630847/gradio-ouputs-keys-of-a-dictionary-instead-of-strings-while-using-openai-chatcom"
  },
  {
    "question": "how to solve the problem of &quot;import gradio could not be resolved&quot;",
    "answer": "<p>firstly make sure that you have installed the library using the following command.</p>\n<pre><code>pip install gradio\n</code></pre>\n<p>The solution is to select the python3 interpreter inside the bin/ folder of the python installed</p>\n<p><a href=\"https://i.sstatic.net/llRJr.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/llRJr.png\" alt=\"vs code python interpreter selector\" /></a></p>\n<p>click on the enter interpreter path here and choose the python3 inside the bin it will get the import error solved.</p>\n<p>in my case i was using a venv so i'm selecting the python3 so that the pylint in the vscode will now the packages.</p>\n<p><a href=\"https://i.sstatic.net/L1Jso.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/L1Jso.png\" alt=\"python3 selection\" /></a></p>\n",
    "link": "https://stackoverflow.com/questions/75633975/how-to-solve-the-problem-of-import-gradio-could-not-be-resolved"
  },
  {
    "question": "How to use Gradio interface to auto submit the audio when recording is done?",
    "answer": "<p>I found the solution. I am putting it here for other's reference.</p>\n<pre><code>import gradio as gr\n\nfrom transformers import pipeline\n\np = pipeline(&quot;automatic-speech-recognition&quot;)\n\ndef transcribe(audio):\n    text = p(audio)[&quot;text&quot;]\n    return text\n\ngr.Interface(\n    fn=transcribe, \n    inputs=gr.Audio(source=&quot;microphone&quot;, type=&quot;filepath&quot;), \n    outputs=&quot;text&quot;,live=True).launch()\n</code></pre>\n<p>Adding live=True serves the purpose.</p>\n",
    "link": "https://stackoverflow.com/questions/74660611/how-to-use-gradio-interface-to-auto-submit-the-audio-when-recording-is-done"
  },
  {
    "question": "How to Output Downloadable file after processing?",
    "answer": "<p>Instead of</p>\n<pre><code>        with gr.Column():\n            file_obj = gr.File(label=&quot;Input File&quot;\n# no any other arguments\n)\n            input= file_obj\n</code></pre>\n<p>Just have</p>\n<pre><code>        with gr.Column():\n            file_obj = gr.File(label=&quot;Input File&quot;)\n            input= file_obj\n\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/75458603/how-to-output-downloadable-file-after-processing"
  },
  {
    "question": "gradio refresh interface when selecting File",
    "answer": "<p>There were many problems with the code (I fixed those not related with the main issue in the original post), but in the end what solved my problem (making the button visible) was that instead to rerender,</p>\n<pre><code>def file_selected():\n    ...\n    process_button.visible=True\n    demo.render()\n</code></pre>\n<p>I just had to return the process_button.update</p>\n<pre><code>def file_selected(file_input):\n    ...\n    return gr.update(visible=True)\n</code></pre>\n<p>(Actually this was documented in gradio's online docs; sorry, I didn't notice it before)</p>\n<p>This is the complete working code:</p>\n<pre><code>import gradio as gr\n\ndef file_selected(file_input):\n    print(&quot;yes, file_selected is invoked&quot;)\n    print(process_button)\n    return gr.update(visible=True)\n    \nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column(scale=1):\n            gr.Markdown(&quot;### Data&quot;)\n            file_input = gr.File(label=&quot;Select File&quot;)\n            process_button = gr.Button(&quot;Process&quot;, visible=False)\n\n        with gr.Column(scale=2, min_width=600):\n            gr.Markdown(&quot;### Output&quot;)\n            result_display = gr.TextArea(default=&quot;&quot;, label=&quot;Result&quot;, lines=10, visible=False)\n\n    file_input.change(fn=file_selected, inputs=file_input, outputs=process_button)\n    \nif __name__ == &quot;__main__&quot;:\n    demo.launch()    \n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/75325378/gradio-refresh-interface-when-selecting-file"
  },
  {
    "question": "gradio importing error on jupyter notebook: SyntaxError: future feature annotations is not defined",
    "answer": "<p>From the traceback it looks like you're using python version 3.6.</p>\n<p>At the moment, gradio supports python versions 3.7 and above (as seen <a href=\"https://pypi.org/project/gradio/\" rel=\"nofollow noreferrer\">here</a>)</p>\n<blockquote>\n<p>Prerequisite: Gradio requires Python 3.7 or higher, that's all!</p>\n</blockquote>\n<p>As mentioned in <a href=\"https://stackoverflow.com/a/52890129/1382495\">this</a> answer, the future feature <code>annotations</code> is only implemented in python 3.7 onwards.</p>\n",
    "link": "https://stackoverflow.com/questions/75160048/gradio-importing-error-on-jupyter-notebook-syntaxerror-future-feature-annotati"
  },
  {
    "question": "Gradio cannot install",
    "answer": "<p>The problem is not related to <code>gradio</code>. You have installed <code>py2app</code> on your Windows but <a href=\"https://pypi.org/project/py2app/\" rel=\"nofollow noreferrer\">https://pypi.org/project/py2app/</a> is only for Mac OS X. Uninstall <code>py2app</code>:</p>\n<pre><code>pip uninstall -y py2app\n</code></pre>\n<p>or remove the directory <code>C:\\Users\\ugurn\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\py2app</code></p>\n",
    "link": "https://stackoverflow.com/questions/74996077/gradio-cannot-install"
  },
  {
    "question": "Messaging/Feedback mechanism in Gradio apps",
    "answer": "<p>You can do this by converting your function into a generator. Basically just change the <code>return</code> keyword to <code>yield</code>. You will also need to enable the <code>.queue()</code>.</p>\n<p>This code should work:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import gradio as gr\nfrom gradio.components import Markdown, Textbox, Button\nfrom time import sleep\n\n\ndef transform(component):\n    for i in range(5):\n        yield str(i)\n        sleep(3)\n    yield f&quot;text -- {i}&quot;\n\n\nwith gr.Blocks() as app:\n    inp = Textbox(label=&quot;Your message&quot;)\n    out = Textbox(label=&quot;Your transformed message&quot;)\n    feedback = Markdown(&quot;Initial&quot;)\n    btn = Button(&quot;See for yourself!&quot;, label=&quot;Run&quot;)\n    btn.click(transform, inputs=inp, outputs=out)\n\napp.queue()\napp.launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/74211548/messaging-feedback-mechanism-in-gradio-apps"
  },
  {
    "question": "How do I successfully deploy a transformer model using Gradio to Hugginface Space?",
    "answer": "<p>Have you declare all the dependency in the requirements.txt file.\nFor reference have a look at this space created by me:\n<a href=\"https://huggingface.co/spaces/abhibisht89/ADR_XTRACTER/tree/main\" rel=\"nofollow noreferrer\">https://huggingface.co/spaces/abhibisht89/ADR_XTRACTER/tree/main</a></p>\n<p>Hope this will be helpful .</p>\n",
    "link": "https://stackoverflow.com/questions/72986713/how-do-i-successfully-deploy-a-transformer-model-using-gradio-to-hugginface-spac"
  },
  {
    "question": "Gradio - Pytorch MNIST Digit Recognizer",
    "answer": "<p>Im sorry if I got your question wrong, but from what I understand you are getting an error when trying to predict the digit using your function predict image.</p>\n<p>So here are two possible hints. Maybe you have implemented them already, but I don't know because of the very small code snippet.</p>\n<p>First of all. Have you set your model into evaluation mode using</p>\n<pre><code>CNN.eval()\n</code></pre>\n<p>Do after you finished training your model and want to evaluate inputs without training the model.</p>\n<p>Second of all, maybe you need to add a fourth dimension to your input tensor &quot;im_resize&quot;. Normally your model expects a dimension for the number of channels, the batch size, the height and the width of your input.\nIn addition I can not tell if your input is a of the datatype torch.tensor . If not transform your array into a tensor first.</p>\n<p>You can add a batch dimension to your input tensor by using</p>\n<pre><code>im_resize = im_resize.unsqueeze(0)\n</code></pre>\n<p>I hope that I understand your question correctly and was able to help you.</p>\n",
    "link": "https://stackoverflow.com/questions/71629683/gradio-pytorch-mnist-digit-recognizer"
  },
  {
    "question": "How can I extract and store the text generated from an automatic speech recognition deep learning app",
    "answer": "<p>You can open up the <code>Interface.from_pipeline</code> abstraction, and define your own <a href=\"https://gradio.app/docs/#interfac\" rel=\"nofollow noreferrer\">Gradio interface</a>. You need to define your own inputs, outputs, and prediction function, thus accessing the text prediction from the model. Here is an example.</p>\n<p>You can test is here <a href=\"https://huggingface.co/spaces/radames/Speech-Recognition-Example\" rel=\"nofollow noreferrer\">https://huggingface.co/spaces/radames/Speech-Recognition-Example</a></p>\n<pre class=\"lang-py prettyprint-override\"><code>\nimport gradio as gr\nfrom transformers import pipeline\n\n\nmodel = pipeline(task=&quot;automatic-speech-recognition&quot;,\n                 model=&quot;facebook/s2t-medium-librispeech-asr&quot;)\n\n\ndef predict_speech_to_text(audio):\n    prediction = model(audio)\n    # text variable contains your voice-to-text string\n    text = prediction['text']\n    return text\n\n\ngr.Interface(fn=predict_speech_to_text,\n             title=&quot;Automatic Speech Recognition (ASR)&quot;,\n             inputs=gr.inputs.Audio(\n                 source=&quot;microphone&quot;, type=&quot;filepath&quot;, label=&quot;Input&quot;),\n             outputs=gr.outputs.Textbox(label=&quot;Output&quot;),\n             description=&quot;Using pipeline with F acebook S2T for ASR.&quot;,\n             examples=['ljspeech.wav'],\n             allow_flagging='never'\n             ).launch()\n</code></pre>\n",
    "link": "https://stackoverflow.com/questions/71568142/how-can-i-extract-and-store-the-text-generated-from-an-automatic-speech-recognit"
  },
  {
    "question": "Exception: MissingSchema with Gradio Library",
    "answer": "<p>This error happens with older versions of Gradio. Please force upgrade to the latest version of <code>Gradio</code> (sometimes colab doesn't do this automatically):</p>\n<p><code>pip install gradio --upgrade</code></p>\n",
    "link": "https://stackoverflow.com/questions/65911420/exception-missingschema-with-gradio-library"
  }
]