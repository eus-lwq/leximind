{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.4985263157894737,
  "eval_steps": 500,
  "global_step": 1335,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02245614035087719,
      "grad_norm": 9.111560821533203,
      "learning_rate": 2.3170731707317075e-05,
      "loss": 6.7973,
      "step": 20
    },
    {
      "epoch": 0.04491228070175438,
      "grad_norm": 3.465017080307007,
      "learning_rate": 4.75609756097561e-05,
      "loss": 3.4488,
      "step": 40
    },
    {
      "epoch": 0.06736842105263158,
      "grad_norm": 2.648658514022827,
      "learning_rate": 4.930448222565688e-05,
      "loss": 2.2672,
      "step": 60
    },
    {
      "epoch": 0.08982456140350877,
      "grad_norm": 2.079418897628784,
      "learning_rate": 4.853168469860897e-05,
      "loss": 2.1049,
      "step": 80
    },
    {
      "epoch": 0.11228070175438597,
      "grad_norm": 2.168055772781372,
      "learning_rate": 4.7758887171561054e-05,
      "loss": 2.0321,
      "step": 100
    },
    {
      "epoch": 0.13473684210526315,
      "grad_norm": 2.242945671081543,
      "learning_rate": 4.698608964451314e-05,
      "loss": 1.8673,
      "step": 120
    },
    {
      "epoch": 0.15719298245614036,
      "grad_norm": 2.091601848602295,
      "learning_rate": 4.6213292117465226e-05,
      "loss": 1.8831,
      "step": 140
    },
    {
      "epoch": 0.17964912280701753,
      "grad_norm": 2.4606142044067383,
      "learning_rate": 4.544049459041731e-05,
      "loss": 1.8763,
      "step": 160
    },
    {
      "epoch": 0.20210526315789473,
      "grad_norm": 2.467458963394165,
      "learning_rate": 4.46676970633694e-05,
      "loss": 1.8543,
      "step": 180
    },
    {
      "epoch": 0.22456140350877193,
      "grad_norm": 3.3737473487854004,
      "learning_rate": 4.3894899536321485e-05,
      "loss": 1.8047,
      "step": 200
    },
    {
      "epoch": 0.24701754385964914,
      "grad_norm": 2.749263286590576,
      "learning_rate": 4.312210200927357e-05,
      "loss": 1.7995,
      "step": 220
    },
    {
      "epoch": 0.2694736842105263,
      "grad_norm": 2.4060134887695312,
      "learning_rate": 4.234930448222566e-05,
      "loss": 1.7932,
      "step": 240
    },
    {
      "epoch": 0.2919298245614035,
      "grad_norm": 2.6448912620544434,
      "learning_rate": 4.1576506955177744e-05,
      "loss": 1.7161,
      "step": 260
    },
    {
      "epoch": 0.3143859649122807,
      "grad_norm": 2.451714038848877,
      "learning_rate": 4.080370942812983e-05,
      "loss": 1.7568,
      "step": 280
    },
    {
      "epoch": 0.3368421052631579,
      "grad_norm": 2.4108712673187256,
      "learning_rate": 4.0030911901081916e-05,
      "loss": 1.7359,
      "step": 300
    },
    {
      "epoch": 0.35929824561403506,
      "grad_norm": 2.5263242721557617,
      "learning_rate": 3.9258114374034e-05,
      "loss": 1.7615,
      "step": 320
    },
    {
      "epoch": 0.3817543859649123,
      "grad_norm": 2.9671404361724854,
      "learning_rate": 3.848531684698609e-05,
      "loss": 1.7931,
      "step": 340
    },
    {
      "epoch": 0.40421052631578946,
      "grad_norm": 2.8462514877319336,
      "learning_rate": 3.7712519319938175e-05,
      "loss": 1.7062,
      "step": 360
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 3.228590250015259,
      "learning_rate": 3.693972179289026e-05,
      "loss": 1.7274,
      "step": 380
    },
    {
      "epoch": 0.44912280701754387,
      "grad_norm": 2.5752294063568115,
      "learning_rate": 3.616692426584235e-05,
      "loss": 1.6425,
      "step": 400
    },
    {
      "epoch": 0.47157894736842104,
      "grad_norm": 2.6817526817321777,
      "learning_rate": 3.5394126738794434e-05,
      "loss": 1.666,
      "step": 420
    },
    {
      "epoch": 0.49403508771929827,
      "grad_norm": 2.3780229091644287,
      "learning_rate": 3.462132921174652e-05,
      "loss": 1.6673,
      "step": 440
    },
    {
      "epoch": 0.5164912280701754,
      "grad_norm": 3.363662004470825,
      "learning_rate": 3.3848531684698606e-05,
      "loss": 1.7478,
      "step": 460
    },
    {
      "epoch": 0.5389473684210526,
      "grad_norm": 2.8310306072235107,
      "learning_rate": 3.307573415765069e-05,
      "loss": 1.6948,
      "step": 480
    },
    {
      "epoch": 0.5614035087719298,
      "grad_norm": 3.3739683628082275,
      "learning_rate": 3.230293663060278e-05,
      "loss": 1.6821,
      "step": 500
    },
    {
      "epoch": 0.583859649122807,
      "grad_norm": 2.861556053161621,
      "learning_rate": 3.1530139103554865e-05,
      "loss": 1.6738,
      "step": 520
    },
    {
      "epoch": 0.6063157894736843,
      "grad_norm": 2.895390510559082,
      "learning_rate": 3.075734157650695e-05,
      "loss": 1.6017,
      "step": 540
    },
    {
      "epoch": 0.6287719298245614,
      "grad_norm": 2.97947096824646,
      "learning_rate": 2.9984544049459044e-05,
      "loss": 1.6146,
      "step": 560
    },
    {
      "epoch": 0.6512280701754386,
      "grad_norm": 3.1422321796417236,
      "learning_rate": 2.921174652241113e-05,
      "loss": 1.6413,
      "step": 580
    },
    {
      "epoch": 0.6736842105263158,
      "grad_norm": 3.0653131008148193,
      "learning_rate": 2.8438948995363217e-05,
      "loss": 1.6119,
      "step": 600
    },
    {
      "epoch": 0.696140350877193,
      "grad_norm": 3.709641933441162,
      "learning_rate": 2.7666151468315303e-05,
      "loss": 1.6854,
      "step": 620
    },
    {
      "epoch": 0.7185964912280701,
      "grad_norm": 2.946779251098633,
      "learning_rate": 2.689335394126739e-05,
      "loss": 1.6496,
      "step": 640
    },
    {
      "epoch": 0.7410526315789474,
      "grad_norm": 3.174957036972046,
      "learning_rate": 2.6120556414219475e-05,
      "loss": 1.6773,
      "step": 660
    },
    {
      "epoch": 0.7635087719298246,
      "grad_norm": 3.1998226642608643,
      "learning_rate": 2.5347758887171562e-05,
      "loss": 1.6112,
      "step": 680
    },
    {
      "epoch": 0.7859649122807018,
      "grad_norm": 3.2804505825042725,
      "learning_rate": 2.4574961360123648e-05,
      "loss": 1.609,
      "step": 700
    },
    {
      "epoch": 0.8084210526315789,
      "grad_norm": 3.7015328407287598,
      "learning_rate": 2.3802163833075734e-05,
      "loss": 1.5841,
      "step": 720
    },
    {
      "epoch": 0.8308771929824561,
      "grad_norm": 3.2200684547424316,
      "learning_rate": 2.302936630602782e-05,
      "loss": 1.6771,
      "step": 740
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 2.752288341522217,
      "learning_rate": 2.2256568778979907e-05,
      "loss": 1.6268,
      "step": 760
    },
    {
      "epoch": 0.8757894736842106,
      "grad_norm": 3.462750196456909,
      "learning_rate": 2.1483771251931993e-05,
      "loss": 1.6235,
      "step": 780
    },
    {
      "epoch": 0.8982456140350877,
      "grad_norm": 3.540475845336914,
      "learning_rate": 2.071097372488408e-05,
      "loss": 1.6497,
      "step": 800
    },
    {
      "epoch": 0.9207017543859649,
      "grad_norm": 3.384458541870117,
      "learning_rate": 1.9938176197836165e-05,
      "loss": 1.6142,
      "step": 820
    },
    {
      "epoch": 0.9431578947368421,
      "grad_norm": 3.117292642593384,
      "learning_rate": 1.916537867078825e-05,
      "loss": 1.5313,
      "step": 840
    },
    {
      "epoch": 0.9656140350877193,
      "grad_norm": 3.3251163959503174,
      "learning_rate": 1.839258114374034e-05,
      "loss": 1.6342,
      "step": 860
    },
    {
      "epoch": 0.9880701754385965,
      "grad_norm": 3.4520797729492188,
      "learning_rate": 1.7619783616692428e-05,
      "loss": 1.6073,
      "step": 880
    },
    {
      "epoch": 1.0101052631578948,
      "grad_norm": 3.457014560699463,
      "learning_rate": 1.6846986089644514e-05,
      "loss": 1.507,
      "step": 900
    },
    {
      "epoch": 1.032561403508772,
      "grad_norm": 4.008735656738281,
      "learning_rate": 1.60741885625966e-05,
      "loss": 1.5175,
      "step": 920
    },
    {
      "epoch": 1.0550175438596492,
      "grad_norm": 3.5691425800323486,
      "learning_rate": 1.5301391035548686e-05,
      "loss": 1.4014,
      "step": 940
    },
    {
      "epoch": 1.0774736842105264,
      "grad_norm": 3.8686680793762207,
      "learning_rate": 1.4528593508500774e-05,
      "loss": 1.4026,
      "step": 960
    },
    {
      "epoch": 1.0999298245614035,
      "grad_norm": 4.246957778930664,
      "learning_rate": 1.375579598145286e-05,
      "loss": 1.4403,
      "step": 980
    },
    {
      "epoch": 1.1223859649122807,
      "grad_norm": 4.016059875488281,
      "learning_rate": 1.2982998454404947e-05,
      "loss": 1.4538,
      "step": 1000
    },
    {
      "epoch": 1.1448421052631579,
      "grad_norm": 3.654787302017212,
      "learning_rate": 1.2210200927357033e-05,
      "loss": 1.3812,
      "step": 1020
    },
    {
      "epoch": 1.167298245614035,
      "grad_norm": 4.269991397857666,
      "learning_rate": 1.143740340030912e-05,
      "loss": 1.444,
      "step": 1040
    },
    {
      "epoch": 1.1897543859649122,
      "grad_norm": 4.002285003662109,
      "learning_rate": 1.0664605873261205e-05,
      "loss": 1.4179,
      "step": 1060
    },
    {
      "epoch": 1.2122105263157894,
      "grad_norm": 3.7875607013702393,
      "learning_rate": 9.891808346213292e-06,
      "loss": 1.393,
      "step": 1080
    },
    {
      "epoch": 1.2346666666666666,
      "grad_norm": 4.0976996421813965,
      "learning_rate": 9.119010819165378e-06,
      "loss": 1.3834,
      "step": 1100
    },
    {
      "epoch": 1.2571228070175438,
      "grad_norm": 3.9993531703948975,
      "learning_rate": 8.346213292117466e-06,
      "loss": 1.432,
      "step": 1120
    },
    {
      "epoch": 1.279578947368421,
      "grad_norm": 5.3978400230407715,
      "learning_rate": 7.573415765069553e-06,
      "loss": 1.3977,
      "step": 1140
    },
    {
      "epoch": 1.3020350877192983,
      "grad_norm": 4.176976203918457,
      "learning_rate": 6.800618238021639e-06,
      "loss": 1.4247,
      "step": 1160
    },
    {
      "epoch": 1.3244912280701755,
      "grad_norm": 4.546407222747803,
      "learning_rate": 6.0278207109737254e-06,
      "loss": 1.4158,
      "step": 1180
    },
    {
      "epoch": 1.3469473684210527,
      "grad_norm": 3.8159854412078857,
      "learning_rate": 5.255023183925812e-06,
      "loss": 1.4092,
      "step": 1200
    },
    {
      "epoch": 1.3694035087719298,
      "grad_norm": 3.606544017791748,
      "learning_rate": 4.482225656877898e-06,
      "loss": 1.3544,
      "step": 1220
    },
    {
      "epoch": 1.391859649122807,
      "grad_norm": 3.9642765522003174,
      "learning_rate": 3.7094281298299846e-06,
      "loss": 1.4053,
      "step": 1240
    },
    {
      "epoch": 1.4143157894736842,
      "grad_norm": 3.6999871730804443,
      "learning_rate": 2.9366306027820713e-06,
      "loss": 1.409,
      "step": 1260
    },
    {
      "epoch": 1.4367719298245614,
      "grad_norm": 4.565295219421387,
      "learning_rate": 2.1638330757341575e-06,
      "loss": 1.3546,
      "step": 1280
    },
    {
      "epoch": 1.4592280701754385,
      "grad_norm": 4.125853061676025,
      "learning_rate": 1.3910355486862442e-06,
      "loss": 1.3545,
      "step": 1300
    },
    {
      "epoch": 1.4816842105263157,
      "grad_norm": 3.9279768466949463,
      "learning_rate": 6.182380216383307e-07,
      "loss": 1.3572,
      "step": 1320
    }
  ],
  "logging_steps": 20,
  "max_steps": 1335,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.249253492080509e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
